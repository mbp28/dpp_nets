{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dpp_nets.layers.layers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "import time\n",
    "import gzip\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from dpp_nets.utils.io import make_embd, make_tensor_dataset, load_tensor_dataset\n",
    "from dpp_nets.utils.io import data_iterator, load_embd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import time\n",
    "from dpp_nets.my_torch.utilities import pad_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data Sets\n",
    "train_set = torch.load('/Users/Max/data/beer_reviews/pytorch/annotated_common.pt')\n",
    "rat_set = torch.load('/Users/Max/data/beer_reviews/pytorch/annotated.pt')\n",
    "embd = load_embd('/Users/Max/data/beer_reviews/pytorch/embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 25\n",
    "_, max_set_size = train_set.data_tensor.size()\n",
    "_, embd_dim = embd.weight.size()\n",
    "\n",
    "hidden_dim = 500\n",
    "enc_dim = 200\n",
    "target_dim = 3 # let's choose the first three aspects to learn!\n",
    "\n",
    "# Baseline\n",
    "baseline_nets = DeepSetBaseline(embd_dim, hidden_dim, enc_dim, target_dim)\n",
    "baseline = nn.Sequential(embd, baseline_nets, nn.Sigmoid())\n",
    "\n",
    "# Model\n",
    "kernel_dim = 200\n",
    "kernel_net = KernelVar(embd_dim, hidden_dim, kernel_dim)\n",
    "sampler = MarginalSampler()\n",
    "pred_net = PredNet(embd_dim, hidden_dim, enc_dim, target_dim)\n",
    "trainer = MarginalTrainer(kernel_net, sampler, pred_net)\n",
    "\n",
    "trainer.reg = 0.1\n",
    "trainer.reg_mean = 10\n",
    "trainer.activation = nn.Sigmoid()\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Rtrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ab813f7b971f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mRtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Backpropagate + parameter updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Rtrainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Actual training loop for model\n",
    "\n",
    "params = [{'params': trainer.kernel_net.parameters(), 'lr': 1e-3},\n",
    "          {'params': trainer.pred_net.parameters(), 'lr': 1e-4}]\n",
    "\n",
    "optimizer = torch.optim.Adam(params)\n",
    "trainer.reg = 0.1\n",
    "\n",
    "for epoch in range(10):\n",
    "    for t, (review, target) in enumerate(train_loader):\n",
    "        words = embd(Variable(review))\n",
    "        target = Variable(target[:,:3])\n",
    "        loss  = Rtrainer(words, target)\n",
    "        \n",
    "        # Backpropagate + parameter updates\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not (t+1) % 10: \n",
    "            print('Loss at it :', t+1, 'is', loss.data[0])\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need also a training script for RTrainer!!\n",
    "sampler = ReinforceSampler(5)\n",
    "Rtrainer = ReinforceTrainer(trainer.kernel_net, sampler, trainer.pred_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual training loop for baseline\n",
    "# Training\n",
    "criterion = nn.MSELoss()\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(baseline_nets.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    for t, (review, target) in enumerate(train_loader):\n",
    "        target = Variable(target[:,:3])\n",
    "        words = Variable(review)\n",
    "        pred = baseline(words)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        # Backpropagate + parameter updates\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not (t+1) % 10: \n",
    "            print('Loss at it :', t+1, 'is', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_baseline(val_set, model, criterion):\n",
    "    x = Variable(val_set.data_tensor, volatile=True)\n",
    "    y = Variable(val_set.target_tensor[:,:3], volatile=True)\n",
    "    pred = model(x)\n",
    "    loss = criterion(pred, y)\n",
    "    print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_model(val_set, model):\n",
    "    model.reg = 0\n",
    "    x = Variable(val_set.data_tensor, volatile=True)\n",
    "    x = embd(x)\n",
    "    y = Variable(val_set.target_tensor[:,:3], volatile=True)\n",
    "    loss = model(x, y)\n",
    "    print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(train_set, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_baseline(train_set, baseline, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def sample(model, sampler, embd, dataset):\n",
    "    rand = random.randint(0, len(dataset))\n",
    "    x = dataset.data_tensor[rand:rand+2]\n",
    "    x = embd(Variable(x))\n",
    "    y = dataset.target_tensor[rand:rand+2]\n",
    "    kernel = trainer.kernel_net(x)\n",
    "    sampler.s_ix = trainer.kernel_net.s_ix\n",
    "    sampler.e_ix = trainer.kernel_net.e_ix\n",
    "    sampler(kernel, x)\n",
    "    print(sampler.saved_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = random.randint(0, len(train_set))\n",
    "x = train_set.data_tensor[rand:rand+10]\n",
    "x = embd(Variable(x))\n",
    "y = Variable(train_set.target_tensor[rand:rand+10,:3])\n",
    "Rtrainer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.data.sum() for l in Rtrainer.sampler.saved_subsets for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = torch.randn(9,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.3224 -0.2710 -1.0688\n",
       " 0.5904  0.7979  0.7390\n",
       "-0.0869  2.1480 -2.9223\n",
       "-1.1593 -0.3784 -0.4341\n",
       " 0.1043 -1.1186  0.7613\n",
       "-0.5970 -1.4440 -2.8684\n",
       "-0.5452 -0.7874 -0.7970\n",
       "-0.8491 -0.9683  0.6335\n",
       "-0.7317 -0.0121  0.5305\n",
       "[torch.FloatTensor of size 9x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       " -1.3224 -0.2710 -1.0688\n",
       "  0.5904  0.7979  0.7390\n",
       " -0.0869  2.1480 -2.9223\n",
       "\n",
       "(1 ,.,.) = \n",
       " -1.1593 -0.3784 -0.4341\n",
       "  0.1043 -1.1186  0.7613\n",
       " -0.5970 -1.4440 -2.8684\n",
       "\n",
       "(2 ,.,.) = \n",
       " -0.5452 -0.7874 -0.7970\n",
       " -0.8491 -0.9683  0.6335\n",
       " -0.7317 -0.0121  0.5305\n",
       "[torch.FloatTensor of size 3x3x3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.view(3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "alpha_iter = 3\n",
    "target_dim = 1\n",
    "target = torch.randn(batch_size * alpha_iter)\n",
    "pred = torch.randn(batch_size * alpha_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = Variable((target - pred).view(batch_size, alpha_iter,target_dim).sum(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.39558482170105, 0.42840495705604553, 0.8365748524665833],\n",
       " [-0.24185743927955627, 0.6139535903930664, 0.8181594610214233],\n",
       " [0.3858824372291565, -1.586434245109558, -0.04904495179653168]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i.data[0] for i in row] for row in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  2.3956\n",
       "  0.4284\n",
       "  0.8366\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.2419\n",
       "  0.6140\n",
       "  0.8182\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0.3859\n",
       " -1.5864\n",
       " -0.0490\n",
       "[torch.FloatTensor of size 3x3x1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
