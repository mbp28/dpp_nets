{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import gzip\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(\"I'm cool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary structure \n",
    "import gzip\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from dpp_nets.utils.io import embd_iterator, make_embd\n",
    "from collections import namedtuple\n",
    "from nltk import word_tokenize\n",
    "\n",
    "id_to_content = {}\n",
    "errors = []\n",
    "#embd_path = '/Users/Max/data/askubuntu/vectors_stackexchange.txt.gz'\n",
    "embd_path = '/Users/Max/data/askubuntu/vectors_pruned.200.txt.gz'\n",
    "embd_layer, word_to_ix  = make_embd(embd_path)\n",
    "question = namedtuple('question', 'id title body title_ix body_ix')\n",
    "path = '/Users/Max/data/askubuntu/text_tokenized.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "max_title_size = 0\n",
    "max_body_size = 0\n",
    "with gzip.open(path, 'rt') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        id, title, body = line.split(\"\\t\")\n",
    "        id = int(id)\n",
    "        if len(title) == 0:\n",
    "            print(id)\n",
    "            empty_cnt += 1\n",
    "            continue\n",
    "            \n",
    "        #title = word_tokenize(title)\n",
    "        #body = word_tokenize(body)\n",
    "        title = title.split()\n",
    "        body = body.split()\n",
    "\n",
    "        # Create title_ix\n",
    "        # title_ix = [word_to_ix[word] + 1 for word in title if word in word_to_ix.keys()]\n",
    "        title_ix = []\n",
    "        for word in title:\n",
    "            if word in word_to_ix:\n",
    "                ix = word_to_ix[word] + 1\n",
    "                title_ix.append(ix)\n",
    "            else:\n",
    "                candidates = re.split('[;|,-/.\"]', word)\n",
    "                for word in candidates:\n",
    "                    if word in word_to_ix:\n",
    "                        ix = word_to_ix[word] + 1\n",
    "                        title_ix.append(ix)\n",
    "        max_title_size = max(max_title_size, len(title_ix))\n",
    "        \n",
    "        # Create body_ix \n",
    "        # body_ix = [word_to_ix[word] + 1 for word in body if word in word_to_ix.keys()]\n",
    "        body_ix = []\n",
    "        for word in body:\n",
    "            if word in word_to_ix:\n",
    "                ix = word_to_ix[word] + 1\n",
    "                body_ix.append(ix)\n",
    "            else:\n",
    "                candidates = re.split('[;|,-/.\"]', word)\n",
    "                for word in candidates:\n",
    "                    if word in word_to_ix:\n",
    "                        ix = word_to_ix[word] + 1\n",
    "                        body_ix.append(ix)\n",
    "                    else:\n",
    "                        errors.append(word)\n",
    "                        \n",
    "        max_body_size = max(max_body_size, len(body_ix))\n",
    "        \n",
    "        content = question(id, title, body, title_ix, body_ix)\n",
    "        id_to_content[id] = content\n",
    "\n",
    "\n",
    "print(errors)\n",
    "print(set(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8ee6bcea0394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Create body_ix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbody_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-8ee6bcea0394>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Create body_ix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbody_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "max_title_size = 0\n",
    "max_body_size = 0\n",
    "\n",
    "with gzip.open(path, 'rt') as f:\n",
    "    for line in f:\n",
    "        id, title, body = line.split(\"\\t\")\n",
    "        id = int(id)\n",
    "        if len(title) == 0:\n",
    "            print(id)\n",
    "            empty_cnt += 1\n",
    "            continue\n",
    "            \n",
    "        # title = word_tokenize(title)\n",
    "        # body = word_tokenize(body)\n",
    "        title = title.split()\n",
    "        body = body.split()\n",
    "\n",
    "        # Create title_ix\n",
    "        title_ix = [word_to_ix[word] + 1 for word in title if word in word_to_ix.keys()]\n",
    "        \n",
    "        # Create body_ix \n",
    "        body_ix = [word_to_ix[word] + 1 for word in body if word in word_to_ix.keys()]\n",
    "        error = [word for word in body if word not in word_to_ix.keys()]\n",
    "        errors.extend(error)\n",
    "        content = question(id, title, body, title_ix, body_ix)\n",
    "        id_to_content[id] = content\n",
    "\n",
    "print(errors)\n",
    "print(set(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92620"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = '/Users/Max/data/askubuntu/train_random.txt'\n",
    "i = 0\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        #parts = line.split(\"\\t\") \n",
    "        #print('ID', parts[0])\n",
    "        #print('Title:', parts[1])\n",
    "        #print('Body:', parts[2])\n",
    "        i += 1\n",
    "        #if i > 25: \n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "question = namedtuple('question', 'id title body title_ix body_ix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = question(12, 'abc', 'def', [3,4,5], [8,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi.body_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "path = '/Users/Max/data/askubuntu/vectors_pruned.200.txt.gz'\n",
    "path = '/Users/Max/data/askubuntu/vectors_stackexchange.txt.gz'\n",
    "e = embd_iterator(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embd_iterator(embd_path):\n",
    "    with gzip.open(embd_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                word = parts[0]\n",
    "                embd = np.array([float(x) for x in parts[1:]])\n",
    "                yield word, embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (word, embd) in e:\n",
    "    print(word)\n",
    "    print(embd)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dpp_nets.utils.io import embd_iterator, make_embd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embd_path = '/Users/Max/data/askubuntu/vectors_stackexchange.txt.gz'\n",
    "    \n",
    "# Create dictionaries\n",
    "ix_to_word = {}\n",
    "ix_to_vecs = {}\n",
    "word_to_ix = {}\n",
    "\n",
    "for ix, (word, vecs) in enumerate(embd_iterator(embd_path)):\n",
    "    ix_to_word[ix] = word\n",
    "    ix_to_vecs[ix] = vecs\n",
    "    word_to_ix[word] = ix\n",
    "\n",
    "vocab_size, embd_dim = len(ix_to_word), len(ix_to_vecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "embd = torch.zeros(1 + vocab_size, embd_dim)\n",
    "\n",
    "for i, vec in enumerate(ix_to_vecs.values(), 1):\n",
    "    try:\n",
    "        embd[i] = torch.FloatTensor(vec)\n",
    "    except:\n",
    "        a, b = i, vec\n",
    "        print('failed')\n",
    "        continue\n",
    "\n",
    "embd_weight_dict = OrderedDict([('weight', embd)])\n",
    "\n",
    "embd_layer = nn.Embedding(1 + vocab_size, embd_dim, padding_idx=0)\n",
    "embd_layer.load_state_dict(embd_weight_dict)\n",
    "embd_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_word[a-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_layer, word_to_ix  = make_embd(embd_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
