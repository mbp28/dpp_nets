{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PIPELINE\n",
    "# feed in a tensor of size batch_size * max_set_size * embd_dim\n",
    "# coud possibly be a packed sequence which includes length information for each batch_size\n",
    "# 0) Assume we have created sequences in DataSet (they are already padded)\n",
    "# 1) Collapse to 2D to feed through kernel embedding\n",
    "# 2) Reconstruct using for-loop the kernel matrix L, do eigendecomposition and sample from DPP\n",
    "# 3) New Kernel should batch_size * alpha_iter * embd_dim (contains summed_selection for each batch + iteration)\n",
    "# 4) Collapse to 2D and feed through prediction network\n",
    "# 5) Get something of size (batch_size x alpha_iter) * target_dim, make target compatible with this\n",
    "# 6) Backpropagate the loss\n",
    "mask = data.abs().sum(2).sign().squeeze()\n",
    "lengths = mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  0  1  1  0\n",
       "  0  1  1  1\n",
       "  1  0  0  0\n",
       "  1  1  1  1\n",
       "  1  0  1  0\n",
       " [torch.FloatTensor of size 5x4], Variable containing:\n",
       "  0  1  1\n",
       "  0  1  0\n",
       "  1  0  1\n",
       "  1  1  1\n",
       "  1  1  0\n",
       " [torch.FloatTensor of size 5x3], Variable containing:\n",
       "  0  0  1  1  1  1\n",
       "  1  1  0  1  0  1\n",
       "  1  0  1  0  1  0\n",
       "  0  1  0  1  0  1\n",
       "  0  1  1  0  0  0\n",
       " [torch.FloatTensor of size 5x6], Variable containing:\n",
       "  1  0  1  1\n",
       "  0  1  1  0\n",
       "  1  0  1  1\n",
       "  0  1  1  1\n",
       "  1  0  1  1\n",
       " [torch.FloatTensor of size 5x4], Variable containing:\n",
       "  0  1  1  1  0\n",
       "  1  0  0  0  1\n",
       "  1  0  0  1  0\n",
       "  0  0  0  1  1\n",
       "  0  0  1  0  0\n",
       " [torch.FloatTensor of size 5x5]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       " [torch.FloatTensor of size 5x2], \n",
       "  0  0  0\n",
       "  0  0  0\n",
       "  0  0  0\n",
       "  0  0  0\n",
       "  0  0  0\n",
       " [torch.FloatTensor of size 5x3], \n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 5], \n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       " [torch.FloatTensor of size 5x2], \n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 5x1]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.zeros(alpha_iter,i) for i in (max_set_size - length.data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.FloatTensor with no dimension]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.zeros(0),torch.zeros(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_hook(i, j):\n",
    "    def my_print(module, grad_in, grad_out):\n",
    "        print(i,j, loss_list[i][j])\n",
    "    return my_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "register_backward_hook() missing 1 required positional argument: 'hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-655102da90d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPPLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mDPPLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_with_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_set_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: register_backward_hook() missing 1 required positional argument: 'hook'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set up data\n",
    "batch_size = 5\n",
    "max_set_size = 6\n",
    "feat_dim = 7\n",
    "target_dim = 3\n",
    "alpha_iter = 5\n",
    "hidden_dim = 10\n",
    "alpha_iter = 2\n",
    "kernel = nn.Linear(feat_dim, hidden_dim)\n",
    "predictor = nn.Linear(feat_dim, target_dim)\n",
    "\n",
    "data = torch.zeros(batch_size, max_set_size, feat_dim)\n",
    "data[0,:4] = torch.randn(4,feat_dim)\n",
    "data[1,:3] = torch.randn(3,feat_dim)\n",
    "data[2,:6] = torch.randn(6,feat_dim)\n",
    "data[3,:4] = torch.randn(4,feat_dim)\n",
    "data[4,:5] = torch.randn(5,feat_dim)\n",
    "data = Variable(data)\n",
    "target = Variable(torch.randn(batch_size, target_dim))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Forward pass\n",
    "mask = data.abs().sum(2).sign().byte()\n",
    "#length = mask.sum(1).squeeze()\n",
    "batch_kernel = kernel(data.masked_select(mask.expand_as(data)).view(-1, feat_dim))\n",
    "#batch_kernel.sum().backward()\n",
    "s = 0\n",
    "samples = [[] for i in range(batch_size)]\n",
    "\n",
    "for i, e in enumerate(length.data):\n",
    "    \n",
    "    A = batch_kernel[s:e]\n",
    "    L = A.mm(A.t())\n",
    "    e, v = custom_eig()(L)\n",
    "    \n",
    "    for j in range(alpha_iter):\n",
    "        subset = DPPLayer()(e,v)\n",
    "        DPPLayer.register_backward_hook(my_hook(i,j))\n",
    "        sample = pad_with_zeros(subset, max_set_size)\n",
    "        samples[i].append(sample)\n",
    "        \n",
    "samples = [torch.stack(i) for i in samples]\n",
    "reps = [samples[i].mm(data[i]) for i in range(batch_size)]\n",
    "big = torch.cat(reps)\n",
    "predictions = predictor(big).view(batch_size, alpha_iter, target_dim)\n",
    "target = target.unsqueeze(1).expand(batch_size, alpha_iter, target_dim)\n",
    "loss = criterion(predictions, target)\n",
    "loss_list = list(((predictions - target)**2).mean(2).view(-1).data)\n",
    "loss_list = list(((predictions - target)**2).mean(2).data)\n",
    "loss_list = [list(i.view(-1)) for i in loss_list]\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_list = list(((predictions - target)**2).mean(2).data)\n",
    "loss_list = [list(i.view(-1)) for i in loss_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  1  1  1  1  0  0\n",
       "  0  1  1  1  0  0\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  0  0  0  0  0  0\n",
       "  1  0  0  0  0  0\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  1  0  1  1  1  0\n",
       "  1  1  0  1  1  1\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  1  1  1  0  0  0\n",
       "  1  1  0  1  0  0\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  0  1  0  1  0  0\n",
       "  0  1  1  0  0  0\n",
       " [torch.FloatTensor of size 2x6]]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = med[start:end]\n",
    "    L = kernel.mm(kernel.t())\n",
    "    e, v = custom_eig()(L)\n",
    "    for j in range(3):\n",
    "        subset = DPP()(e, v)\n",
    "        my_list[i].append(subset)\n",
    "    start = end\n",
    "new_list = [torch.stack(l) for l in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues and eigenvectors\n",
      "CVT error:  1.85858762189e-15\n",
      "CVT error:  1.1633811087e-14\n",
      "adj error:  8.881784197e-16\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-43f4e4a05c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#A = torch.Tensor(A).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Set-up\n",
    "# THIS COULD BE IT!!\n",
    "# THIS IS IT!\n",
    "# Let's do it!\n",
    "\n",
    "N = 3\n",
    "A = torch.randn(N,N).double()\n",
    "A = A.mm(A.t())\n",
    "#A = torch.Tensor(A).float()\n",
    "e, v = torch.eig(A, eigenvectors=True)\n",
    "e = e[:,0]\n",
    "\n",
    "\n",
    "\n",
    "# Random perturbation for forward\n",
    "dA = torch.randn(N,N)\n",
    "E = e.expand(N,N) - e.expand(N,N).t()\n",
    "F = 1 / (E + torch.eye(N)) - torch.eye(N)\n",
    "P = v.inverse().mm(dA).mm(v)\n",
    "de = torch.eye(N) * P\n",
    "dv = v.mm(F * P)\n",
    "\n",
    "# random perturbation for backward\n",
    "be = torch.randn(N).diag()\n",
    "bv = torch.randn(N, N)\n",
    "#be = torch.ones(N).diag()\n",
    "#bv = torch.ones(N, N)\n",
    "med = be + F * (v.t().mm(bv))\n",
    "bA = v.t().inverse().mm(med).mm(v.t())\n",
    "\n",
    "print('adj error: ',torch.sum(dA*bA)-torch.sum(de*be)-torch.sum(dv*bv))\n",
    "bA\n",
    "\n",
    "# Check forward pass using analytic function and complex matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues and eigenvectors\n",
      "CVT error:  10.7986414951\n",
      "CVT error:  3.06826003225\n",
      "adj error:  4.4408920985e-16\n"
     ]
    }
   ],
   "source": [
    "# Checking SVD IN NUMPY!!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# General Set-up\n",
    "N = 4\n",
    "A = 0.1 * np.random.randn(N, N) + np.diag(np.arange(1, N+1))\n",
    "B = np.random.randn(N, N)\n",
    "I = np.eye(N)\n",
    "dA = np.random.randn(N, N)\n",
    "dB = np.random.randn(N, N)\n",
    "bC = np.random.randn(N, N)\n",
    "eps = 1e-20\n",
    "epsi = 1 / eps\n",
    "Ae = A + 1j*eps*dA\n",
    "Be = B + 1j*eps*dB\n",
    "\n",
    "# SVD\n",
    "u, s, vT = np.linalg.svd(A)\n",
    "s = np.diag(s)\n",
    "\n",
    "De, Du =np.linalg.eig(Ae.dot(Ae.T))\n",
    "D = np.real(De)\n",
    "U = np.real(Ue)\n",
    "\n",
    "# make dC diagonal equal to zero\n",
    "Ue = Ue.dot(np.diag(1 / np.diag(np.linalg.inv(U).dot(Ue))))\n",
    "E = np.outer(np.ones(N), D) - np.outer(D, np.ones(N))\n",
    "F = 1 / (E + np.eye(N)) - np.eye(N)\n",
    "P = np.linalg.inv(U).dot(dA.dot(U))\n",
    "dD = np.eye(N) * P\n",
    "dU = U.dot(F*P)\n",
    "\n",
    "bD = np.diag(np.random.randn(N))\n",
    "bU = np.random.randn(N,N)\n",
    "bD = bD + F * (U.T.dot(bU))\n",
    "bA = np.linalg.inv(U.T).dot(bD.dot(U.T))\n",
    "print('eigenvalues and eigenvectors')\n",
    "print('CVT error: ', np.linalg.norm(np.diag(dD)-epsi*np.imag(De)))\n",
    "print('CVT error: ', np.linalg.norm(dU-epsi*np.imag(Ue)))\n",
    "print('adj error: ',np.sum(dA*bA)-np.sum(dD*bD)-np.sum(dU*bU))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "De, Du =np.linalg.eig(Ae.dot(Ae.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.75808267 -5.96442145e-20j,  16.56881395 +5.61666792e-20j,\n",
       "         3.77822669 +1.92363529e-20j,   8.72362952 +4.89203296e-20j])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "De"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul received an invalid combination of arguments - got (complex), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mcomplex\u001b[0m)\n * (torch.DoubleTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mcomplex\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ecf5b3a6aaa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mepsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mAe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1j\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Max/Coding/anaconda2/envs/torch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0m__rmul__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mul received an invalid combination of arguments - got (complex), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mcomplex\u001b[0m)\n * (torch.DoubleTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mcomplex\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "# Let's do the above thing for SVD!!\n",
    "# First just do it theoretically, then try with my auto_grad\n",
    "from dpp_nets.my_torch.linalg import custom_svd\n",
    "\n",
    "M = 4\n",
    "N = 5\n",
    "eps = 1e-20\n",
    "epsi = 1 / eps\n",
    "dA = torch.randn(M, N).double()\n",
    "\n",
    "A = torch.randn(M,N).double()\n",
    "vecs, vals, v = torch.svd(A, some=False) # M x M, M, N x N\n",
    "\n",
    "# Random perturbation for forward pass\n",
    "utdAv = vecs.t().mm(dA).mm(v) #M x N\n",
    "dP1 = utdAv[:,:M] # M x M\n",
    "dP2 = utdAv[:,M:] # M x (N - M)\n",
    "dS = utdAv.diag() # M\n",
    "E = vals.expand(M,M) - vals.expand(M,M).t() # mask\n",
    "F = 1 / (E + torch.eye(M).double()) - torch.eye(M).double()\n",
    "dC = F * (dP1.mm(vals.diag()) + vals.diag().mm(dP1.t()))\n",
    "dU = vecs.mm(dC)\n",
    "dvals = dS\n",
    "dvecs = dU\n",
    "\n",
    "# Backward PASS\n",
    "bvals = torch.randn(M).diag().double()\n",
    "bvecs = torch.randn(M, M).double()\n",
    "bP1 = (vecs.t() * F).mm(bvecs).mm(vals.diag()) + bvecs.t().mm(vecs * F.t()).mm(vals.diag())\n",
    "med = bvals + bP1\n",
    "bA = vecs.mm(med).mm(v[:,:M].t())\n",
    "\n",
    "# Now check it\n",
    "print('adj error: ',torch.sum(dA*bA)-torch.sum(dvals*bvals.diag())-torch.sum(dvecs*bvecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.0997\n",
       " 0.3033\n",
       "-1.5958\n",
       " 0.7418\n",
       "[torch.DoubleTensor of size 4]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.2665  0.1132 -1.0704 -0.6101 -1.0782\n",
       " 0.3332 -0.1740  1.1825  0.1516  0.1103\n",
       " 0.1841  0.0268 -0.9359  0.1113 -0.7498\n",
       " 0.2306  0.4855 -0.0951 -0.1724  0.2393\n",
       "[torch.DoubleTensor of size 4x5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.mm(bvals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0642  0.5162  1.8358  1.8688\n",
       " 1.5988  1.5422 -1.0641 -0.7090\n",
       " 0.3098 -0.4780 -0.0715  0.2414\n",
       " 1.1151 -0.9208 -0.7757 -0.1190\n",
       "[torch.FloatTensor of size 4x4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_var = Variable(A, requires_grad=True)\n",
    "e_var, v_var = custom_eig()(A_var)\n",
    "be_var = torch.FloatTensor(be.diag())\n",
    "bv_var = torch.FloatTensor(bv)\n",
    "e_var.backward(be_var, retain_variables=True)\n",
    "v_var.backward(bv_var)\n",
    "bA = A_var.grad.data\n",
    "bA\n",
    "\n",
    "# artificial forward pass - simply re-use the tensors from the other cell\n",
    "# in fact by showing that the backward gradients agree, we have already established proof of concept\n",
    "print('adj error: ',torch.sum(dA*bA)-torch.sum(de*be)-torch.sum(dv*bv))\n",
    "bA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scalability - Flexible batch_size\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(10)\n",
    "batch_size = 5\n",
    "max_set_size = 6\n",
    "feat_dim = 4\n",
    "hidden_dim = 300\n",
    "data = torch.randn(batch_size, max_set_size, feat_dim)\n",
    "model = nn.Linear(feat_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now make it tensor-ready\n",
    "mask, _ = data.abs().max(dim=2)\n",
    "length = mask.sign().sum(dim=1).squeeze()\n",
    "mask = mask.sign().expand_as(data).byte()\n",
    "\n",
    "my_input = Variable(data, requires_grad=True)\n",
    "compressed = my_input.masked_select(Variable(mask)).view(-1,feat_dim)\n",
    "med = model(compressed)\n",
    "\n",
    "# now do the eigendecomposition (for this need to re-assemble the tensor again)\n",
    "# this probably needs a for-loop :(((((\n",
    "# for i in range(batch_size):\n",
    "start = 0 \n",
    "my_list = [[] for i in range(batch_size)]\n",
    "for i, end in enumerate(length.cumsum(0).long()):\n",
    "    kernel = med[start:end]\n",
    "    L = kernel.mm(kernel.t())\n",
    "    e, v = custom_eig()(L)\n",
    "    for j in range(3):\n",
    "        subset = DPP()(e, v)\n",
    "        my_list[i].append(subset)\n",
    "    start = end\n",
    "new_list = [torch.stack(l) for l in my_list]\n",
    "\n",
    "#loss = torch.stack(my_list)\n",
    "#final = loss.sum()\n",
    "#final.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "def custom_decomp(Function):\n",
    "    \n",
    "    def forward(mat):\n",
    "        vecs, vals, _  = torch.svd(mat)\n",
    "        vals.pow_(2)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
