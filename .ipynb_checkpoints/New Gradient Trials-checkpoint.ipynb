{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The old notebook became too confusing!\n",
    "\n",
    "# Trying to check Singular Values and Singular Vectors in Numpy\n",
    " \n",
    "import numpy as np\n",
    "\n",
    "# General Set-up\n",
    "N = 2\n",
    "A = 0.1 * np.random.randn(N, N) + np.diag(np.arange(1, N+1))\n",
    "B = np.random.randn(N, N)\n",
    "I = np.eye(N)\n",
    "dA = np.random.randn(N, N)\n",
    "dB = np.random.randn(N, N)\n",
    "bC = np.random.randn(N, N)\n",
    "eps = 1e-20\n",
    "epsi = 1 / eps\n",
    "Ae = A + 1j*eps*dA\n",
    "Be = B + 1j*eps*dB # don't need it, I'm working with single input.\n",
    "\n",
    "# SVD Set-up\n",
    "u, s, vT = np.linalg.svd(A)\n",
    "\n",
    "# Complex part\n",
    "De, Du = np.linalg.eig(Ae.dot(Ae.T))\n",
    "Du, _, _ = np.linalg.svd(Ae)\n",
    "idx = De.argsort()[::-1]   \n",
    "De = De[idx]\n",
    "Du = u[:,idx]\n",
    "D = np.real(De) # only needed for what? \n",
    "\n",
    "# forward propagation \n",
    "dA = dA\n",
    "dS = np.diag(I * u.T.dot(dA).dot(vT.T))\n",
    "\n",
    "E = np.outer(np.ones(N), s) - np.outer(s, np.ones(N))\n",
    "F = 1 / (E + np.eye(N)) - np.eye(N)\n",
    "dU = u.dot(F * (u.T.dot(dA).dot(vT.T).dot(np.diag(s)) + np.diag(s).dot(vT).dot(dA.T).dot(u)))\n",
    "\n",
    "# backward gradients\n",
    "bS = np.random.randn(N) # gradients wrt singular values\n",
    "bA = u.dot(np.diag(bS)).dot(vT) # backpropagated gradient wrt to matrix A\n",
    "\n",
    "print('singular value')\n",
    "print('svd error: ', (np.linalg.norm(s-np.sqrt(D))))\n",
    "\n",
    "# Forward Check based on complex matrices\n",
    "print('CVT error (vals): ', (np.linalg.norm(2*s*dS - epsi*np.imag(De))))\n",
    "print('CVT error (vecs): ', (np.linalg.norm(dU - epsi*np.imag(Du))))\n",
    "\n",
    "# Backward Check, these are essentially two traces!!\n",
    "print('adj error: ',np.sum(dA*bA)-np.sum(dS*bS))\n",
    "\n",
    "# I should be able to use the same identity for my testing purposes!!!\n",
    "# trace(bC.T * dC) = trace(bA.T * dA) + trace(bB.T * dB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Checking eigenvectors and eigenvalues in Numpy\n",
    "np.random.seed(10)\n",
    "# General Set-up\n",
    "N = 5\n",
    "A = 0.1 * np.random.randn(N, N) + np.diag(np.arange(1, N+1))\n",
    "#A = A.dot(A.T)\n",
    "B = np.random.randn(N, N)\n",
    "I = np.eye(N)\n",
    "dA = np.random.randn(N, N)\n",
    "dB = np.random.randn(N, N)\n",
    "bC = np.random.randn(N, N)\n",
    "eps = 1e-20\n",
    "epsi = 1 / eps\n",
    "Ae = A + 1j*eps*dA\n",
    "Be = B + 1j*eps*dB\n",
    "\n",
    "# EIGEN Set-up\n",
    "De, Ue = np.linalg.eig(Ae)\n",
    "D = np.real(De)\n",
    "U = np.real(Ue)\n",
    "\n",
    "# make dC diagonal equal to zero\n",
    "Ue = Ue.dot(np.diag(1 / np.diag(np.linalg.inv(U).dot(Ue))))\n",
    "E = np.outer(np.ones(N), D) - np.outer(D, np.ones(N))\n",
    "F = 1 / (E + np.eye(N)) - np.eye(N)\n",
    "P = np.linalg.inv(U).dot(dA.dot(U))\n",
    "dD = np.eye(N) * P\n",
    "dU = U.dot(F*P)\n",
    "#dD, dU = forward(A, dA)\n",
    "\n",
    "bD = np.diag(np.random.randn(N)) # random perturbation of eigenvalues\n",
    "bU = np.random.randn(N,N) # random perturbation of eigenvectors\n",
    "bD = bD + F * (U.T.dot(bU))\n",
    "bA = np.linalg.inv(U.T).dot(bD.dot(U.T))\n",
    "print('eigenvalues and eigenvectors')\n",
    "print('CVT error (vals): ', np.linalg.norm(np.diag(dD) - epsi*np.imag(De)))\n",
    "print('CVT error (vecs): ', np.linalg.norm(dU - epsi*np.imag(Ue)))\n",
    "print('adj error (backward): ', np.sum(dA*bA)-np.sum(dD*bD)-np.sum(dU*bU))\n",
    "#print('CVT error (vecs): ', np.linalg.norm(np.abs(dU) - np.abs(epsi*np.imag(Ue))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials for eig in PyTorch\n",
    "import torch\n",
    "\n",
    "N = 5\n",
    "A = torch.randn(N,N).double()\n",
    "L = A.mm(A.t())\n",
    "I = torch.eye(N).double()\n",
    "dA = torch.randn(N, N).double() \n",
    "dL = dA.mm(A.t()) + A.mm(dA.t())\n",
    "\n",
    "vals, vecs = torch.eig(L, eigenvectors=True)\n",
    "vals = vals[:,0]\n",
    "E = vals.expand(N,N) - vals.expand(N,N).t()\n",
    "F = 1 / (E + I) - I\n",
    "P = torch.inverse(vecs).mm(dL.mm(vecs))\n",
    "dvals = I * P\n",
    "dvecs = vecs.mm(F*P)\n",
    "\n",
    "# backward pass\n",
    "bvals = torch.randn(N).diag().double()\n",
    "bvecs = torch.randn(N,N).double()\n",
    "med = bvals + F * (vecs.t().mm(bvecs))\n",
    "bL = torch.inverse(vecs.t()).mm(med.mm(vecs.t()))\n",
    "bA = bL.mm(A) + bL.t().mm(A)\n",
    "\n",
    "# check\n",
    "torch.sum(bA * dA) - torch.sum(dvals * bvals) - torch.sum(dvecs * bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.881784197001252e-16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# essentials for svd in PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "M = 6\n",
    "N = 5\n",
    "A = torch.randn(M,N).double()\n",
    "dA = torch.randn(M, N).double() \n",
    "dL = dA.mm(A.t()) + A.mm(dA.t())\n",
    "\n",
    "vecs, vals, v = torch.svd(A)\n",
    "vals = vals**2\n",
    "s = vals.size(0)\n",
    "I = torch.eye(s).double()\n",
    "E = vals.expand(s,s) - vals.expand(s,s).t()\n",
    "F = 1 / (E + I) - I\n",
    "P = vecs.t().mm(dL.mm(vecs))\n",
    "dvals = I * P\n",
    "dvecs = vecs.mm(F*P)\n",
    "\n",
    "# backward pass\n",
    "bvals = torch.randn(s).diag().double()\n",
    "bvecs = torch.randn(vecs.size()).double()\n",
    "med = bvals + F * (vecs.t().mm(bvecs))\n",
    "bL = vecs.mm(med.mm(vecs.t()))\n",
    "bA = bL.mm(A) + bL.t().mm(A)\n",
    "\n",
    "# check\n",
    "torch.sum(bA * dA) - torch.sum(dvals * bvals) - torch.sum(dvecs * bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from dpp_nets.my_torch.linalg import custom_decomp\n",
    "\n",
    "A = Variable(A, requires_grad=True)\n",
    "vals, vecs = custom_decomp()(A)\n",
    "torch.autograd.backward([vals, vecs],[bvals.diag(), bvecs])\n",
    "torch.sum(A.grad.data == bA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
