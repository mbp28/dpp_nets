{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dpp_nets.my_torch as my_torch\n",
    "import torch\n",
    "import numpy as np\n",
    "from dpp_nets.my_torch.controlvar import compute_alpha\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "network_params = {'emb_in': 300, 'emb_h': 200, 'emb_out': 100,\n",
    "                  'pred_in': 150, 'pred_h': 100, 'pred_out': 1,\n",
    "                  'set_size': 40} \n",
    "dtype = torch.DoubleTensor\n",
    "\n",
    "train_iter_base = 200\n",
    "batch_size = 10\n",
    "train_iter = batch_size * train_iter_base\n",
    "sample_iter = 1\n",
    "alpha_iter = 0\n",
    "lr = 1e-5\n",
    "weight_decay = 0\n",
    "reg_exp = 1\n",
    "reg_var = 0\n",
    "\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def plot_moving_average(plot_dict, name, n=200):\n",
    "    temp = {k: torch.mean(torch.stack(v)) for k,v in plot_dict.items()}\n",
    "    x, y = zip(*sorted(temp.items()))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x = moving_average(x, n)\n",
    "    y = moving_average(y, n)\n",
    "    plt.plot(x,y)\n",
    "    plt.title(\"Loss (Moving Average)\")\n",
    "    plt.savefig(str(name) + \".pdf\", format='pdf')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Training Iteration')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_iter = 0\n",
    "overwrite = 0\n",
    "\n",
    "set_seed(10)\n",
    "baseline_0 = my_torch.DPPRegressor(network_params, dtype)\n",
    "baseline_0.sample()\n",
    "\n",
    "set_seed(13)\n",
    "baseline_0.train_with_baseline(train_iter, batch_size, sample_iter, alpha_iter, lr, weight_decay, reg_exp, reg_var, overwrite)\n",
    "baseline_0.evaluate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_iter = 0\n",
    "overwrite = 500\n",
    "\n",
    "set_seed(10)\n",
    "baseline_500 = my_torch.DPPRegressor(network_params, dtype)\n",
    "baseline_500.sample()\n",
    "\n",
    "set_seed(13)\n",
    "baseline_500.train_with_baseline(train_iter, batch_size, sample_iter, alpha_iter, lr, weight_decay, reg_exp, reg_var, overwrite)\n",
    "baseline_500.evaluate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_iter = 5\n",
    "overwrite = 0\n",
    "batch_size = 20\n",
    "lr = 1e-5\n",
    "reg_exp = 1000\n",
    "set_seed(10)\n",
    "model = my_torch.DPPRegressor(network_params, dtype)\n",
    "model.sample()\n",
    "\n",
    "set_seed(13)\n",
    "model.train_with_baseline(train_iter, batch_size, sample_iter, alpha_iter, lr, weight_decay, reg_exp, reg_var, overwrite)\n",
    "model.evaluate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: torch.var(torch.stack(v)) for k,v in model.alpha_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isinf(model.alpha_dict[0][0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = model.embedding.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = model.subset.data.diag().numpy()\n",
    "index = index.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subembd = embd[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submatrix = subembd.dot(subembd.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submatinv = np.linalg.inv(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(1).clamp(-.1,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(280):\n",
    "    print(np.sum(np.isinf(model.alpha_dict[i][0].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moving_average(baseline_0.loss_dict, \"alpha0\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moving_average(baseline_500.loss_dict, \"alpha500\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moving_average(model.loss_dict, \"alpha_est\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_iter = 5\n",
    "\n",
    "set_seed(10)\n",
    "model = my_torch.DPPRegressor(network_params, dtype)\n",
    "model.sample()\n",
    "\n",
    "set_seed(13)\n",
    "model.train_with_baseline(train_iter, batch_size, sample_iter, alpha_iter, lr, weight_decay, reg_exp, reg_var)\n",
    "model.evaluate(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar = compute_covar(torch.stack(model.a_score_dict[0]), torch.stack(model.a_reinforce_dict[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar.squeeze(0)[24] / torch.var(torch.stack(model.a_score_dict[0]), dim=0).squeeze(0)[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.alpha_dict[0][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_alpha(model.a_reinforce_dict[0], model.a_score_dict[0])[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(model.alpha.numpy())[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isinf(model.alpha.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((model.alpha.numpy())>1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Dict\n",
    "print(\"Loss Dict: \", {k: torch.mean(torch.stack(v)) for k,v in baseline.loss_dict.items()},\"\\n\")\n",
    "# Pred Dict\n",
    "print(\"Pred Dict: \", {k: torch.mean(torch.stack(v)) for k,v in baseline.pred_dict.items()},\"\\n\")\n",
    "# Subset Sizes\n",
    "print(\"Subset Dict: \", {k: torch.sum(torch.stack(v)) for k,v in baseline.subset_dict.items()},\"\\n\")\n",
    "# Weights in Prediction Layer\n",
    "print(\"Prediction Dict: \", {k: torch.mean(torch.stack(v)) for k,v in baseline.pred_w2_mean.items()},\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Dict\n",
    "print(\"Loss Dict: \", {k: torch.mean(torch.stack(v)) for k,v in baseline.loss_dict.items()},\"\\n\")\n",
    "# Pred Dict\n",
    "print(\"Pred Dict: \", {k: torch.mean(torch.stack(v)) for k,v in baseline.pred_dict.items()},\"\\n\")\n",
    "# Subset Sizes\n",
    "print(\"Subset Dict: \", {k: torch.sum(torch.stack(v)) for k,v in baseline.subset_dict.items()},\"\\n\")\n",
    "# Weights in Prediction Layer\n",
    "print(\"Weights: \", {k: torch.mean(torch.stack(v)) for k,v in baseline.pred_w2_mean.items()},\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.pred_w1_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(plot_dict1, plot_dict2, smooth=0):\n",
    "\n",
    "    plot_dict1 = {k: torch.stack(v).mean() for k, v in plot_dict1.items()}\n",
    "    plot_dict2 = {k: torch.stack(v).mean() for k, v in plot_dict2.items()}\n",
    "    \n",
    "    if not smooth:        \n",
    "        x, y = zip(*sorted(plot_dict1.items()))\n",
    "        plt.plot(x, y,\"blue\")     \n",
    "        x, y = zip(*sorted(plot_dict2.items()))\n",
    "        plt.plot(x, y,\"red\")      \n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        x = list(plot_dict1.keys())\n",
    "        y = list(plot_dict1.values())\n",
    "        x_sm = np.array(x)\n",
    "        y_sm = np.array(y)\n",
    "        x_smooth = np.linspace(x_sm.min(), x_sm.max(), smooth)\n",
    "        y_smooth = spline(x, y, x_smooth)\n",
    "        plt.plot(x_smooth, y_smooth,\"blue\")\n",
    "        \n",
    "        x = list(plot_dict2.keys())\n",
    "        y = list(plot_dict2.values())\n",
    "        x_sm = np.array(x)\n",
    "        y_sm = np.array(y)\n",
    "        x_smooth = np.linspace(x_sm.min(), x_sm.max(), smooth)\n",
    "        y_smooth = spline(x, y, x_smooth)\n",
    "        plt.plot(x_smooth, y_smooth,\"red\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model.loss_dict, model.loss_dict, smooth=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline = my_torch.DPPRegressor(network_params, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.evaluate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_covar(scores, reinforce_grads):\n",
    "    scores = scores - torch.mean(scores, dim=0).expand_as(scores)\n",
    "    reinforce_grads = reinforce_grads - torch.mean(reinforce_grads, dim=0).expand_as(reinforce_grads)\n",
    "    cov_reinforce_score = torch.mean(reinforce_grads * scores, dim=0)\n",
    "    return cov_reinforce_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = baseline_0.embedding.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = embd.dot(embd.T)\n",
    "res = np.random.choice(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
