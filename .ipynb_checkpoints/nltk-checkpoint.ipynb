{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from dpp_nets.utils.io import make_embd, make_tensor_dataset\n",
    "from dpp_nets.my_torch.utilities import pad_tensor\n",
    "\n",
    "from dpp_nets.layers.layers import DeepSetBaseline\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Baseline (Deep Sets) Trainer')\n",
    "\n",
    "parser.add_argument('-a', '--aspect', type=str, choices=['aspect1', 'aspect2', 'aspect3', 'all'],\n",
    "                    help='what is the target?', required=True)\n",
    "parser.add_argument('--remote', type=int,\n",
    "                    help='training locally or on cluster?', required=True)\n",
    "\n",
    "parser.add_argument('--data_path_local', type=str, default='/Users/Max/data/beer_reviews',\n",
    "                    help='where is the data folder locally?')\n",
    "parser.add_argument('--data_path_remote', type=str, default='/cluster/home/paulusm/data/beer_reviews',\n",
    "                    help='where is the data folder?')\n",
    "\n",
    "parser.add_argument('--ckp_path_local', type=str, default='/Users/Max/checkpoints/beer_reviews',\n",
    "                    help='where is the data folder locally?')\n",
    "\n",
    "parser.add_argument('--ckp_path_remote', type=str, default='/cluster/home/paulusm/checkpoints/beer_reviews',\n",
    "                    help='where is the data folder?')\n",
    "\n",
    "parser.add_argument('-b', '--batch-size', default=50, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 50)')\n",
    "parser.add_argument('--epochs', default=100, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "#parser.add_argument('--lr-k', '--learning-rate-k', default=0.1, type=float,\n",
    "#                    metavar='LRk', help='initial learning rate for kernel net')\n",
    "#parser.add_argument('--lr-p', '--learning-rate-p', default=0.1, type=float,\n",
    "#                    metavar='LRp', help='initial learning rate for pred net')\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-4, type=float,\n",
    "                    metavar='LR', help='initial learning rate for baseline')\n",
    "#parser.add_argument('--reg', type=float, required=True,\n",
    "#                    metavar='reg', help='regularization constant')\n",
    "#parser.add_argument('--reg-mean', type=float, required=True,\n",
    "#                    metavar='reg_mean', help='regularization_mean')\n",
    "\n",
    "args = parser.parse_args(\"-a all --remote 0\".split())\n",
    "\n",
    "val_path   = os.path.join(args.data_path_local, str.join(\".\",['reviews', args.aspect, 'heldout.txt.gz']))\n",
    "embd_path = os.path.join(args.data_path_local, 'review+wiki.filtered.200.txt.gz')\n",
    "#embd, word_to_ix = make_embd(embd_path)\n",
    "#val_set = make_tensor_dataset(val_path, word_to_ix)\n",
    "#val_loader = DataLoader(val_set, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path   = os.path.join(args.data_path_local, str.join(\".\",['reviews', args.aspect, 'train.txt.gz']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dpp_nets.utils.language import create_clean_vocabulary\n",
    "nlp, vocab, embd = create_clean_vocabulary(embd_path, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embd.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dpp_nets.utils.language import BeerDataset, process_batch\n",
    "from torch.utils.data import DataLoader\n",
    "ds = BeerDataset(val_path)\n",
    "dl = DataLoader(ds, 1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object filter_stops.<locals>.<genexpr> at 0x15e5433b8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_stops(doc.sents[0], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yield_sen_vec(doc, vocab, embd):\n",
    "    seen = set()\n",
    "    for s in doc.sents:\n",
    "        t = tuple((filter_stops(s, vocab)))\n",
    "        if t and t not in seen:\n",
    "            seen.add(t)\n",
    "            ixs = torch.LongTensor([vocab.word2index[word] for word in t])\n",
    "            embd_mat = embd(Variable(ixs)).mean(0)\n",
    "            yield embd_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_sens(nlp, vocab, embd, batch):\n",
    "\n",
    "    MAX_CHUNK_LENGTH = 271\n",
    "    MAX_SENS_NO = 105\n",
    "\n",
    "    # maxi = 0\n",
    "    # for review in batch['review']:\n",
    "     #   doc = nlp(review)\n",
    "     #   rep = torch.stack(list(yield_chunk_vec(doc, vocab, embd))).squeeze()\n",
    "     #   maxi = max(maxi, rep.size(0))\n",
    "\n",
    "    reps = []\n",
    "    for review in batch['review']:\n",
    "        doc = nlp(review)\n",
    "        rep = torch.stack(list(yield_sen_vec(doc, vocab, embd))).squeeze()\n",
    "        rep = torch.cat([rep, Variable(torch.zeros(MAX_SENS_NO + 1 - rep.size(0),rep.size(1)))],dim=0)\n",
    "        reps.append(rep)\n",
    "\n",
    "    data_tensor =  torch.stack(reps)\n",
    "    target_tensor = Variable(torch.stack(batch['target']).t().float())\n",
    "    \n",
    "    return data_tensor, target_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor sizes at /Users/soumith/miniconda2/conda-bld/pytorch_1493757319118/work/torch/lib/TH/generic/THTensorMath.c:2559",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-ed36df146d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprocess_batch_sens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-bf8b413d0eed>\u001b[0m in \u001b[0;36mprocess_batch_sens\u001b[0;34m(nlp, vocab, embd, batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_sen_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SENS_NO\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mreps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Max/Coding/anaconda2/envs/torch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(iterable, dim)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Max/Coding/anaconda2/envs/torch/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor sizes at /Users/soumith/miniconda2/conda-bld/pytorch_1493757319118/work/torch/lib/TH/generic/THTensorMath.c:2559"
     ]
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    process_batch_sens(nlp, vocab, embd, batch)\n",
    "    print(\"it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(batch['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep = torch.stack(list(yield_sen_vec(doc, vocab, embd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       " 1.00000e-02 *\n",
       "  -3.3197 -2.1010  0.5291 -1.9777 -1.3976 -0.8817 -1.9846  3.0683  4.7460\n",
       "\n",
       "Columns 9 to 17 \n",
       " 1.00000e-02 *\n",
       "  -1.0821 -1.3740  0.3159 -8.2889 -0.6303  0.6024 -1.4511  0.0689  4.2517\n",
       "\n",
       "Columns 18 to 26 \n",
       " 1.00000e-02 *\n",
       "  -1.0880  2.1262 -3.9885  0.5087  0.3286 -2.4016  3.2297 -0.1347  1.0552\n",
       "\n",
       "Columns 27 to 35 \n",
       " 1.00000e-02 *\n",
       "   4.4200  0.4033  0.7295  5.2747 -2.7575  0.5672  1.6264  2.8517 -2.6457\n",
       "\n",
       "Columns 36 to 44 \n",
       " 1.00000e-02 *\n",
       "   4.8357  2.7553  4.5996  3.7097  0.2618  2.1422 -5.2945 -2.1196  3.3232\n",
       "\n",
       "Columns 45 to 53 \n",
       " 1.00000e-02 *\n",
       "   0.9283 -0.2785 -1.7446  7.1017 -0.1707  3.5888  1.9642  1.1067  3.1421\n",
       "\n",
       "Columns 54 to 62 \n",
       " 1.00000e-02 *\n",
       "  -8.7054 -2.8809  0.5332  2.3658  2.0471 -1.2367  3.2145  2.4289  0.1758\n",
       "\n",
       "Columns 63 to 71 \n",
       " 1.00000e-02 *\n",
       "  -2.1849  3.8908 -0.3796 -2.2982 -1.7284 -3.1314  2.8882 -3.8213  0.4452\n",
       "\n",
       "Columns 72 to 80 \n",
       " 1.00000e-02 *\n",
       "   2.2826 -8.8782 -8.7559  1.6344 -7.1991 -2.0021  1.3367  1.0148 -1.7727\n",
       "\n",
       "Columns 81 to 89 \n",
       " 1.00000e-02 *\n",
       "  -1.5598 -3.5134 -2.5307  0.2536  3.6408  2.5214 -1.6127  2.0498 -2.2867\n",
       "\n",
       "Columns 90 to 98 \n",
       " 1.00000e-02 *\n",
       "   5.9190  2.2379 -5.3552 -2.8290 -0.6606  2.9787  1.2166  0.6425  1.7561\n",
       "\n",
       "Columns 99 to 107 \n",
       " 1.00000e-02 *\n",
       "  -2.7922  0.8930 -1.8945  1.6802 -4.4277 -4.5132  4.6289 -3.6893 -2.8209\n",
       "\n",
       "Columns 108 to 116 \n",
       " 1.00000e-02 *\n",
       "   0.7265 -1.4033 -1.2720  5.3417 -2.7215 -1.6858 -0.7793  3.7721  0.1150\n",
       "\n",
       "Columns 117 to 125 \n",
       " 1.00000e-02 *\n",
       "  -1.7203  3.2830  0.6761  0.1304  4.2975  0.8946 -1.1793  0.5735 -4.7240\n",
       "\n",
       "Columns 126 to 134 \n",
       " 1.00000e-02 *\n",
       "  -0.5792 -1.8901  0.6494  8.2662 -1.9833  0.6249 -2.9249 -4.0434 -0.9216\n",
       "\n",
       "Columns 135 to 143 \n",
       " 1.00000e-02 *\n",
       "   1.1140  0.5746 -1.1947 -5.7900  1.9367 -0.2176  2.9063 -3.6818  2.8534\n",
       "\n",
       "Columns 144 to 152 \n",
       " 1.00000e-02 *\n",
       "   6.1548  3.3893  1.3615  4.7630 -6.4530 -7.8753 -3.8628  0.1793 -2.9093\n",
       "\n",
       "Columns 153 to 161 \n",
       " 1.00000e-02 *\n",
       "   1.9285 -0.8045 -2.7497 -0.1056 -2.3404 -0.9028  4.7138  2.3882 -0.7041\n",
       "\n",
       "Columns 162 to 170 \n",
       " 1.00000e-02 *\n",
       "   0.7772 -3.0659  2.3531 -1.0753 -1.5565 -0.5867  5.9409  1.3111 -1.0584\n",
       "\n",
       "Columns 171 to 179 \n",
       " 1.00000e-02 *\n",
       "  -0.2833 -1.5923  1.7830 -6.1974  1.5827  5.2090 -0.1298 -2.6627 -3.1629\n",
       "\n",
       "Columns 180 to 188 \n",
       " 1.00000e-02 *\n",
       "  -1.6650  4.7779  7.8455  1.3964 -1.5802  7.6934 -3.2991  5.6061 -1.4302\n",
       "\n",
       "Columns 189 to 197 \n",
       " 1.00000e-02 *\n",
       "   5.5291  0.9698  0.1186 -3.2102  2.7103  4.5641 -2.2514 -3.0011  2.0644\n",
       "\n",
       "Columns 198 to 199 \n",
       " 1.00000e-02 *\n",
       "  -3.0103 -2.0719\n",
       "[torch.FloatTensor of size 1x1x200]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[corked, 750ml, bottle, bought, at, the, brewery, (, 74/90, ), a, :, nice, ,, deep, reddish, brown, color, s, :, sour, nose, is, evident, but, not, the, traditional, ,, acetic, acid, cantillon, style, ,, a, bit, sweeter, t, :, nice, sour, taste, with, quality, leaning, more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc, ., ), ,, a, touch, of, sweetness, but, not, distracting, ,, also, not, as, lively, on, the, tongue, as, a, traditional, lambic, m, :, nice, and, drinkable, d, :, good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[750ml]\n",
      "[750ml, bottle, bought, at, the, brewery, (, 74/90, ), a, :, nice, ,, deep, reddish, brown, color, s, :, sour, nose]\n",
      "[bought, at, the, brewery, (, 74/90, ), a, :, nice, ,, deep, reddish, brown, color, s, :, sour, nose]\n",
      "[at, the, brewery, (, 74/90, )]\n",
      "[the]\n",
      "[the, brewery, (, 74/90, )]\n",
      "[(]\n",
      "[74/90]\n",
      "[)]\n",
      "[a, :]\n",
      "[:]\n",
      "[nice, ,]\n",
      "[,]\n",
      "[deep]\n",
      "[reddish]\n",
      "[brown]\n",
      "[reddish, brown, color]\n",
      "[nice, ,, deep, reddish, brown, color, s, :]\n",
      "[:]\n",
      "[sour]\n",
      "[a, :, nice, ,, deep, reddish, brown, color, s, :, sour, nose]\n",
      "[is]\n",
      "[is, evident, but, not, the, traditional, ,, acetic, acid, cantillon, style, ,, a, bit, sweeter, t, :, nice, sour, taste, with, quality, leaning, more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[but]\n",
      "[not]\n",
      "[the]\n",
      "[traditional, ,]\n",
      "[,]\n",
      "[acetic]\n",
      "[acid]\n",
      "[acid, cantillon]\n",
      "[not, the, traditional, ,, acetic, acid, cantillon, style, ,, a, bit, sweeter, t, :, nice, sour, taste, with, quality, leaning, more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[,]\n",
      "[a]\n",
      "[a, bit]\n",
      "[sweeter]\n",
      "[a, bit, sweeter, t]\n",
      "[:]\n",
      "[nice]\n",
      "[sour]\n",
      "[nice, sour, taste, with, quality, leaning, more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[with, quality, leaning, more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[quality]\n",
      "[quality, leaning, more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[more, to, the, musty, side, than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[to, the, musty, side]\n",
      "[the]\n",
      "[musty]\n",
      "[the, musty, side]\n",
      "[than, sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[sharp, ,]\n",
      "[,]\n",
      "[pucker]\n",
      "[sharp, ,, pucker, quality, of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[of, the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[the]\n",
      "[the, framboises, of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[of, (, cantillon, ,, de, ranke, ,, etc]\n",
      "[(]\n",
      "[(, cantillon, ,, de, ranke, ,, etc]\n",
      "[,]\n",
      "[de]\n",
      "[de, ranke, ,, etc]\n",
      "[,]\n",
      "[etc]\n",
      "[.]\n",
      "[)]\n",
      "[,]\n",
      "[a]\n",
      "[a, touch, of, sweetness, but, not, distracting, ,, also, not, as, lively, on, the, tongue, as, a, traditional, lambic, m, :, nice, and, drinkable, d, :, good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[of, sweetness, but, not, distracting, ,, also, not, as, lively, on, the, tongue, as, a, traditional, lambic, m, :, nice, and, drinkable, d, :, good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[sweetness, but, not, distracting, ,, also, not, as, lively, on, the, tongue, as, a, traditional, lambic, m, :, nice, and, drinkable, d, :, good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[but]\n",
      "[not]\n",
      "[not, distracting, ,, also, not, as, lively]\n",
      "[,]\n",
      "[also]\n",
      "[not]\n",
      "[not, as]\n",
      "[not, as, lively]\n",
      "[on, the, tongue, as, a, traditional, lambic]\n",
      "[the]\n",
      "[the, tongue, as, a, traditional, lambic]\n",
      "[as, a, traditional, lambic]\n",
      "[a]\n",
      "[traditional]\n",
      "[a, traditional, lambic]\n",
      "[not, distracting, ,, also, not, as, lively, on, the, tongue, as, a, traditional, lambic, m, :, nice, and, drinkable, d, :, good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[:]\n",
      "[nice, and, drinkable, d, :, good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[and]\n",
      "[drinkable]\n",
      "[d]\n",
      "[:]\n",
      "[good, but, not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[but]\n",
      "[not]\n",
      "[as]\n",
      "[not, as, refreshing, as, the, more, sour, styles, \n",
      "]\n",
      "[as, the, more, sour, styles, \n",
      "]\n",
      "[the]\n",
      "[more]\n",
      "[sour]\n",
      "[the, more, sour, styles, \n",
      "]\n",
      "[\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(list(token.subtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " ( 0 ,.,.) = \n",
       "   0.0401 -0.0321  0.0022  ...   0.0296 -0.0333 -0.0324\n",
       "   0.0262 -0.0066  0.0012  ...   0.0100  0.0024  0.0241\n",
       "   0.0074 -0.0470 -0.0709  ...   0.0741  0.0061 -0.0962\n",
       "            ...             ⋱             ...          \n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " [torch.FloatTensor of size 1x398x200], Variable containing:\n",
       "  0.9000  0.6000  0.7000\n",
       " [torch.FloatTensor of size 1x3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_batch(nlp, vocab, embd, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " ( 0 ,.,.) = \n",
       "   0.0401 -0.0321  0.0022  ...   0.0296 -0.0333 -0.0324\n",
       "   0.0309 -0.0121 -0.0182  ...   0.0245 -0.0340  0.0031\n",
       "  -0.0481 -0.0979  0.0453  ...   0.0285  0.0128 -0.0342\n",
       "            ...             ⋱             ...          \n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " [torch.FloatTensor of size 1x106x200], Variable containing:\n",
       "  0.9000  0.6000  0.7000\n",
       " [torch.FloatTensor of size 1x3])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_batch_sens(nlp, vocab, embd, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cat([rep, Variable(torch.zeros(maxi + 1 - rep.size(0),rep.size(1)))],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for chunk in list(yield_chunks(doc, vocab)):\n",
    "    c = embd(Variable(chunk)).mean(0)\n",
    "    l.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "anno_path = os.path.join(args.data_path_local, 'annotations.json')\n",
    "\n",
    "class BeerDatasetAnnotated(Dataset):\n",
    "    \"\"\"BeerDataset.\"\"\"\n",
    "\n",
    "    def __init__(self, anno_path, aspect='all'):\n",
    "        \n",
    "        # Compute size of the data set      \n",
    "        self.aspect = aspect\n",
    "        \n",
    "\n",
    "        self.lines = []\n",
    "        with open(anno_path) as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "\n",
    "                # Get doc\n",
    "                doc = nlp(ast.literal_eval(item['raw'])['review/text']\n",
    "\n",
    "                # Get annotations\n",
    "                a0 = item['0']\n",
    "                a1 = item['1']\n",
    "                a2 = item['2']\n",
    "\n",
    "                # Get target\n",
    "                target = item['y']\n",
    "\n",
    "                self.lines.append((doc,(a0, a1, a2), target))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.lines[idx]            \n",
    "        sample = {'review': instance[0], 'target': instance[2]}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = BeerDataset(val_path)\n",
    "dl = DataLoader(ds, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dpp_nets.my_torch.utilities import pad_tensor\n",
    "\n",
    "def filter_stops(tree, vocab):\n",
    "    return (token.text for token in tree if not token.is_stop and token.text in vocab.word2index)\n",
    "\n",
    "#def yield_words(doc, vocab)\n",
    "\n",
    "def yield_chunks(doc, vocab, MAX_CHUNK_LENGTH):\n",
    "    seen = set()\n",
    "    for token in doc:\n",
    "        t = tuple((filter_stops(token.subtree, vocab)))\n",
    "        if t and t not in seen:\n",
    "            seen.add(t)\n",
    "            #ixs = [vocab.word2index[word] if word in vocab.word2index else print(word) for word in t]\n",
    "            ixs = torch.LongTensor([vocab.word2index[word] for word in t])\n",
    "            ixs = pad_tensor(ixs,0,0,MAX_CHUNK_LENGTH)\n",
    "            yield ixs\n",
    "            \n",
    "def yield_sentences(doc, vocab, MAX_SENTENCE_LENGTH):\n",
    "    seen = set()\n",
    "    for sen in doc.sents:\n",
    "        t = tuple((filter_stops(sen)))\n",
    "        if t and t not in seen:\n",
    "            seen.add(t)\n",
    "            #ixs = [vocab.word2index[word] for word in t]\n",
    "            ixs = torch.LongTensor([vocab.word2index[word] for word in t])\n",
    "            ixs = pad_tensor(ixs,0,0,MAX_SENTENCE_LENGTH)\n",
    "            yield ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210000it [33:12, 105.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import tqdm\n",
    "MAX_SENS_NO = 0\n",
    "\n",
    "with gzip.open(train_path, 'rt') as f:\n",
    "    for line in tqdm.tqdm(f):\n",
    "        target, sep, review = line.partition('\\t')\n",
    "        doc = nlp(review)\n",
    "        MAX_SENS_NO = max(len(list(doc.sents)), MAX_SENS_NO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENS_NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(short_path, 'wt') as f:\n",
    "    for line in lines[:100]:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_CHUNK_LENGTH = max([len(m) for l in measure_list for m in l])\n",
    "Max_CHUNK_NO = max([len(l) for l in measure_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.symbols import nsubj, VERB\n",
    "\n",
    "sentence = list(doc.sents)[5]\n",
    "for token in sentence:\n",
    "    #print(token, list(token.children), token.head, token.dep_, list(token.lefts), list(token.rights), list(token.subtree))\n",
    "    #print(token, list(token.subtree)) #,list(token.lefts),list(token.rights),token.left_edge, token.right_edge)\n",
    "    print((token, list(token.subtree)))\n",
    "    #print(token, list(token.ancestors))\n",
    "    #print(token, token.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iterator(data_path):\n",
    "    with gzip.open(data_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            target, sep, words = line.partition(\"\\t\")\n",
    "            words, target = words.split(), target.split()\n",
    "            if len(words):\n",
    "                target = torch.Tensor([float(v) for v in target])\n",
    "                yield words, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = 0\n",
    "maxi = 0\n",
    "mean = M2 = 0.0\n",
    "\n",
    "with gzip.open(val_path, 'rt') as f:\n",
    "    for line in f:\n",
    "        target, sep, review = line.partition(\"\\t\")\n",
    "        n_sentences = len(nltk.sent_tokenize(review))\n",
    "        x = n_sentences\n",
    "        \n",
    "        n += 1\n",
    "        if x == 101: \n",
    "            break\n",
    "        maxi = max(x, maxi)\n",
    "        delta = x - mean\n",
    "        mean += delta/n\n",
    "        delta2 = x - mean\n",
    "        M2 += delta*delta2\n",
    "\n",
    "        #i += 1\n",
    "        #if i > 21:\n",
    "         #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to create sentences from a review\n",
    "sentences = nltk.sent_tokenize(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to create words from a sentence\n",
    "words = nltk.word_tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to remove stop words from a sentence\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "operators = set(('no', 'not'))\n",
    "punctuation = set(string.punctuation)\n",
    "stop = (set(stopwords.words('english')) | punctuation) - operators \n",
    "fwords = [[word for word in words if word not in stop] for words in [nltk.word_tokenize(sen) for sen in sentences]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to create bigrams (after stop-word removal? - would do so)\n",
    "\n",
    "print(list(nltk.bigrams(words)))\n",
    "print(30*'-')\n",
    "list(nltk.bigrams(fwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "anno_path = os.path.join(args.data_path_local, 'annotations.json')\n",
    "def read_rationales(path):\n",
    "    \"\"\"\n",
    "    This reads the json.annotations file. \n",
    "    Creates a list of dictionaries, which holds the 994 reviews for which\n",
    "    sentence-level annotations are available. \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    fopen = gzip.open if path.endswith(\".gz\") else open\n",
    "    with fopen(path) as fin:\n",
    "        for line in fin:\n",
    "            item = json.loads(line)\n",
    "            data.append(item)\n",
    "    return data\n",
    "\n",
    "rationales = read_rationales(anno_path)\n",
    "\n",
    "rationales[0].keys()\n",
    "\n",
    "nltk.sent_tokenize(rationales[1]['raw'])[10]\n",
    "\n",
    "import string\n",
    "raw = \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in rationales[2]['x']]).strip()\n",
    "nltk.sent_tokenize(raw)\n",
    "\n",
    "print(rationales[2]['2'][0])\n",
    "rationales[2]['x'][49:63]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "doc = nlp(ast.literal_eval(data[0]['raw']) ['review/text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[0]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import tqdm\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "path = os.path.join(args.data_path_local, str.join(\".\",['reviews', args.aspect, 'heldout.txt.gz']))\n",
    "def simple_iterator(path):\n",
    "    with gzip.open(path, 'rt') as f:\n",
    "        for line in f:\n",
    "            target, sep, review = line.partition(\"\\t\")\n",
    "            yield review, target\n",
    "            \n",
    "# Create set of filtered sentences for each review:\n",
    "operators = set(('no', 'not'))\n",
    "punctuation = set(string.punctuation)\n",
    "stop = set(stopwords.words('english')) | punctuation | set('...')  - operators \n",
    "\n",
    "for review, target in tqdm.tqdm(simple_iterator(path)):\n",
    "\n",
    "    # Split review into sentences\n",
    "    sens = nltk.sent_tokenize(review)\n",
    "    \n",
    "    # Split each sentence into words\n",
    "    sens = [nltk.word_tokenize(sen) for sen in sens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    fwords = [[word for word in sen if word not in stop] for sen in sens]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Noun-Chunks\n",
    "def noun_chunks(doc):\n",
    "    my_processed_review = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk = tuple(filter(lambda token: not token.is_stop, chunk))\n",
    "        chunk = tuple(word.text for word in chunk)\n",
    "        my_processed_review.append(chunk)\n",
    "    my_processed_review = list(filter(None, my_processed_review))\n",
    "    return my_processed_review\n",
    "\n",
    "# Sub-Trees\n",
    "def sub_trees(doc):\n",
    "    my_processed_review = []\n",
    "    for sen in doc.sents:\n",
    "        for token in sen:\n",
    "            chunk = token.subtree\n",
    "            chunk = tuple(filter(lambda token: not token.is_stop, chunk))\n",
    "            #chunk = tuple(word.text for word in chunk)\n",
    "            my_processed_review.append(chunk)\n",
    "    my_processed_review = list(filter(None, my_processed_review))\n",
    "    my_processed_review = list(set(my_processed_review))\n",
    "    return my_processed_review\n",
    "\n",
    "# Sentence-Level processing. \n",
    "def sentences(doc):\n",
    "    my_processed_review = []\n",
    "    for sen in doc.sents:\n",
    "        chunk = tuple(token for token in sen if not token.is_stop)\n",
    "        chunk = tuple(word.text for word in chunk)\n",
    "        my_processed_review.append(chunk)\n",
    "    my_processed_review = list(filter(None, my_processed_review))\n",
    "    return my_processed_review\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
