import dpp_nets.my_torch 
import numpy as np 
class DPP_Regressor(nn.Module):
    
    def __init__(self, network_params, dtype):
        """
        Arguments:
        - network_params: see below for which parameters must specify
        - dtype: torch.DoubleTensor or torch.FloatTensor
        """
        super(DPP_Regressor, self).__init__()
        
        # Read in parameters
        self.set_size = network_params['set_size'] # 40
        self.emb_in = network_params['emb_in']
        self.emb_h = network_params['emb_h']
        self.emb_out = network_params['emb_out']
        self.pred_in = network_params['pred_in'] 
        self.pred_h = network_params['pred_h']
        self.pred_out = network_params['pred_out']
        assert int(self_emb_in / 2) == self.pred_in
        self.dtype = dtype

        # Initialize Network
        self.emb_layer = torch.nn.Sequential(nn.Linear(self.emb_in, self.emb_h), nn.ELU(),
                                             nn.Linear(self.emb_h, self.emb_out))
        self.dpp_layer = my_torch.DPPLayer(self.dtype)
        self.prediction_layer = torch.nn.Sequential(nn.Linear(self.pred_in, self.pred_h), nn.ReLU(), 
                                                    nn.Linear(self.pred_h, self.pred_out))
        # Choose MSELoss as training criterion
        self.criterion = nn.MSELoss()

        # Useful intermediate variables 
        self.embedding = None
        self.subset = None
        self.pick = None
        self.pred = None

        self.type(self.dtype)


    def forward(self, words, context):
        """
        words: Tensor of dimension [set_size, word_emb_dim]
        contexts: Tensor of dimension [set_size, word_emb_dim]
        The rows of x2 are all identical and equal the sum
        across rows of x1 (context to predict DPP embedding)
        self.emb_dim must be 2 * word_emb_dim
        """
        # Concatenate individual words and set context
        x = torch.cat([words, context], dim = 1)

        # Compute embedding of DPP kernel
        self.embedding = self.emb_layer(x)

        # Sample a subset of words from the DPP
        self.subset = self.dpp_layer(self.embedding)
        
        # Filter out the selected words and combine them
        self.pick = self.subset.mm(words).sum(0)

        # Compute a prediction based on the sampled words
        self.pred = self.prediction_layer(self.filtered)

        return self.pred

    def generate(self):
        """
        Each training instance consists of a set of words (2D array) whose words come from a random
        number (between 1 and 20) of different clusters. In total, there exist self.pred_in / GLUE 
        different clusters. Each cluster contains standard random normal noise in most dimensions,
        except for GLUE dimensions, in which its entries are generated by a normal distribution around
        50. These signal dimensions differ across all clusters. 
        """
        GLUE = 5
        SIGNAL = 50

        words = np.random.randn(self.set_size, self.pred_in)

        # Sample a number of clusters (between 1 and 20) present in training instance
        n_clusters = 1 + np.random.choice(20,1) 
        # Will repeat cluster indices to fill upto set_size
        rep = (self.set_size // n_clusters) + 1 

        # Sample cluster indices 
        clusters = np.random.choice(self.pred_in // GLUE, n_clusters, replace=False)

        # Find column indices associated with cluster indices
        col_idx = np.array([np.arange(i*GLUE, i*GLUE + GLUE) for i in clusters]).flatten()
        # Repeat indices to fill upto set_size 
        col_idx = np.tile(col_idx, rep)[:(self.set_size * GLUE)]

        # Overwrite training data with signal according to column indices
        words[np.repeat(np.arange(40), GLUE), col_idx] = np.random.normal(SIGNAL, 1, (self.set_size * GLUE))

        # Create context 
        context = np.tile(np.sum(words, axis=0), (self.set_size, 1))

        # Shuffle, so it doesn't learn to always choose the first item for example.
        np.random.shuffle(words)

        # Wrap into Variables 
        words = Variable(self.dtype(words))
        context = Variable(self.dtype(context))
        target = Variable(self.dtype([n_clusters]))

        return words, context, target 

    def sample(self):
        """
        Demonstrates how Network is currently performing
        by classifying a random instance 
        """

        # Sample
        words, context, target = self.generate()

        # Assigns prediction to self.pred
        self.forward(words, context)

        # Print a couple of messages
        print("Target sampled was: ", target.data[0])
        print("Network predicted: ", self.pred.data[0])
        print("Resulting loss is: ", self.criterion(self.pred, target))

        print("Prediction was based on ", self.subset.data.sum(), "observations.")

        return (self.pred, y), (x1, x2)
    
    def train(self, train_iter, batch_size, lr, reg):
        
        self.lr = lr
        self.batch_size = batch_size
        
        self.optimizer = optim.SGD([{'params': self.emb_layer.parameters(), 'weight_decay': self.reg_kern},
                                    {'params': self.prediction_layer.parameters()}],
                                    lr = self.lr / self.batch_size)

        for t in range(train_iter):
            x1, x2, y, _ = self.gen_data()
            #print("x is", x,"y is", y)
            #self.x_dict[t].append(x.data)
            #self.y_dict[t].append(y.data)
            
            mod_grad = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: (grad_in[0] * loss.data[0],))
            y_pred = self.forward(x1, x2)
            
            self.y_pred_dict[t].append(y_pred.data)
            self.emb_dict[t].append(self.embedding.data)
            self.subset_dict[t].append(self.subset.data)
            self.summed_dict[t].append(self.filtered_and_summed_x.data)

            loss = self.criterion(y_pred,y)
            #print()
            self.loss_dict[t].append(loss.data)
            reg_loss = loss + reg * torch.pow(torch.trace(self.embedding),2)
            
            reg_loss.backward()

            mod_grad.remove()
            
            if (t + 1) % self.batch_size == 0:
                self.optimizer.step()
                self.optimizer.zero_grad()

            if (t + 1) % 50 == 0:
                print(t + 1, loss.data[0])
                
            #exp_lr_scheduler(self.optimizer, t, lr_decay=lr_decay, lr_decay_step=ev_step)
            
    def train_with_baseline(self, train_iter, batch_size, sample_iter, alpha_iter, lr, reg_kern, aggregate=False):
        
        # Prepare Optimizer
        optimizer = optim.SGD([{'params': self.emb_layer.parameters(), 
                                'weight_decay': reg_kern * batch_size * sample_iter},
                               {'params': self.prediction_layer.parameters()}], 
                              lr = lr / (batch_size * sample_iter))
        
        # Clear dictionaries
        self.score_dict.clear()
        self.score_mean.clear()
        self.score_var.clear()
        self.reinforce_dict.clear()
        self.reinforce_mean.clear()
        self.reinforce_var.clear()
        self.loss_dict.clear()
        self.loss_mean.clear()
        self.loss_var.clear()
        self.mod_dict.clear()
        self.mod_mean.clear()
        self.mod_var.clear()
        
        for t in range(train_iter):
            
            self.weight_norm_1[t] = torch.mean(torch.pow(self.emb_layer[0].weight.data,2))
            self.weight_max_1[t] = torch.max(torch.pow(self.emb_layer[0].weight.data,2))
            self.weight_norm_2[t] = torch.mean(torch.pow(self.emb_layer[2].weight.data,2))
            self.weight_max_2[t] = torch.max(torch.pow(self.emb_layer[2].weight.data,2))

            # Draw a Training Sample
            words, context, y = self.generate()
            
            # Save score, build reinforce gradient, save reinforce gradient
            save_score = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: self.a_score_dict[t].append(grad_in[0].data))
            reinforce_grad = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: (grad_in[0] * (loss.data[0]),))
            save_reinforce = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: self.a_reinforce_dict[t].append(grad_in[0].data))
            
            # Estimate alpha
            if alpha_iter:
                for i in range(alpha_iter):                                      
                    y_pred = self.forward(x1, x2)
                    loss = self.criterion(y_pred, y)
                    loss.backward()

                self.alpha = compute_alpha(self.a_reinforce_dict[t], self.a_score_dict[t], False, True, False).double()
                self.zero_grad()
                self.alphas[t].append(self.alpha)
                
            else:
                self.alpha = torch.zeros(self.embedding.size()).double()
                #self.alpha = 0
                    
            save_score.remove()
            reinforce_grad.remove()
            save_reinforce.remove()
            
            # now actual training
            # save scores, reinforce, implement baseline gradient, save baseline gradient
            save_score = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: self.score_dict[t].append(grad_in[0].data))
            save_reinforce = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: self.reinforce_dict[t].append(grad_in[0].data * loss.data[0]))
            modify_grad = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: (Variable(grad_in[0].data * (loss.data[0] - self.alpha)),))
            save_modified = self.dpp_layer.register_backward_hook(lambda module, grad_in, grad_out: self.mod_dict[t].append(grad_in[0].data))

            # sample multiple times from the DPP and backpropagate associated gradients!
            for i in range(sample_iter):
                y_pred = self.forward(x1, x2)
                loss = self.criterion(y_pred, y)
                self.loss_dict[t].append(loss.data) # save_loss
                loss.backward()

            # update parameters after processing a batch
            if (t + 1) % self.batch_size == 0:
                self.optimizer.step()
                self.optimizer.zero_grad()

            # print loss
            if (t + 1) % 50 == 0:
                print(t + 1, loss.data[0])
                
            save_score.remove()
            save_reinforce.remove()
            modify_grad.remove()
            save_modified.remove()

            
            # anneal learning rate
            #exp_lr_scheduler(self.optimizer, t, lr_decay=lr_decay, lr_decay_step=ev_step)
                
        # Update Dictionaries
        self.score_mean = {k: torch.mean(torch.stack(v)) for k, v in self.score_dict.items()}
        self.score_var  = {k: torch.mean(torch.var(torch.stack(v), dim=0)) for k, v in self.score_dict.items()}
        self.score_coef = {k: torch.mean(torch.std(torch.stack(v), dim=0) / torch.mean(torch.stack(v), dim=0))
                          for k, v in self.score_dict.items()}

        self.reinforce_mean = {k: torch.mean(torch.stack(v)) for k, v in self.reinforce_dict.items()}
        self.reinforce_var  = {k: torch.mean(torch.var(torch.stack(v), dim=0)) for k, v in self.reinforce_dict.items()}
        self.reinforce_coef = {k: torch.mean(torch.std(torch.stack(v), dim=0) / torch.mean(torch.stack(v), dim=0))
                          for k, v in self.reinforce_dict.items()}

        self.loss_mean = {k: torch.mean(torch.stack(v)) for k, v in self.loss_dict.items()}
        self.loss_var  = {k: torch.mean(torch.var(torch.stack(v), dim=0)) for k, v in self.loss_dict.items()}
        self.loss_coef = {k: torch.mean(torch.std(torch.stack(v), dim=0) / torch.mean(torch.stack(v), dim=0))
                          for k, v in self.loss_coef.items()}

        self.mod_mean = {k: torch.mean(torch.stack(v)) for k, v in self.mod_dict.items()}
        self.mod_var  = {k: torch.mean(torch.var(torch.stack(v), dim=0)) for k, v in self.mod_dict.items()}
        self.mod_coef = {k: torch.mean(torch.std(torch.stack(v), dim=0) / torch.mean(torch.stack(v), dim=0))
                          for k, v in self.mod_dict.items()}

                        
    def evaluate(self, test_iter):

        loss = 0.0
        subset_count = 0.0
        
        for t in range(test_iter):
            words, context, target = self.generate()
            self.forward(x1, x2)
            loss += self.criterion(self.pred, target)
            subset_count += self.subset.data.sum()
            
        print("Average Loss is: ", loss / test_iter) 
        print("Average Subset Size is: ", subset_count / test_iter)
        
    def reset_parameter(self):
        self.emb_layer[0].reset_parameters()
        self.emb_layer[2].reset_parameters()
        self.prediction_layer[0].reset_parameters()
        self.prediction_layer[2].reset_parameters()
        
        self.optimizer = optim.SGD([{'params': self.emb_layer.parameters(), 'weight_decay': self.reg_kern},
                                    {'params': self.prediction_layer.parameters()}],
                                    lr = self.lr / self.batch_size)
