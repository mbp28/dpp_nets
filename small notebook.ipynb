{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dpp_nets.dpp as dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpp.sample_dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "A = numpy.random.rand(10,10)\n",
    "L = A.dot(A.T)\n",
    "e, v = numpy.linalg.eig(L)\n",
    "subset = dpp.sample_dpp(e, v, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import dpp_nets.dpp as dpp\n",
    "\n",
    "class DPP(Function):\n",
    "    \"\"\"\n",
    "    Uses Numpy Functions to sample from the DPP implicitly \n",
    "    defined through embd, returns score as a gradient in the\n",
    "    backward computation (needs to be complemented by hooks\n",
    "    for REINFORCE or control variate training)\n",
    "\n",
    "    Arguments:\n",
    "    Depending on whether you're training Double or Float, provide\n",
    "    dtype = torch.FloatTensor\n",
    "    dtype = torch.DoubleTensor\n",
    "    \"\"\"\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, embd):\n",
    "\n",
    "        # Perform SVD to get eigenvalue decomposition of L\n",
    "        u1, s, u2 = torch.svd(embd)\n",
    "        e = torch.pow(s,2).numpy()\n",
    "        v = u1.numpy()\n",
    "\n",
    "        # Sample subset from the DPP\n",
    "        subset = torch.from_numpy(dpp.sample_dpp(e, v, one_hot=True))\n",
    "        subset = subset.type(self.dtype)\n",
    "        # Save tensors for backward (gradient computation)\n",
    "        self.save_for_backward(embd, subset)\n",
    "\n",
    "        return subset\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        embd, subset = self.saved_tensors\n",
    "        embd, subset = embd.numpy(), subset.numpy()\n",
    "        score = torch.from_numpy(dpp.score_dpp(embd, subset))\n",
    "\n",
    "        return score.type(self.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "import dpp_nets.my_torch as my_torch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "#dtype = torch.DoubleTensor\n",
    "my_layer = my_torch.DPPLayer(dtype)\n",
    "A = Variable(torch.randn(10,10), requires_grad=True)\n",
    "subset = my_layer(A)\n",
    "l = torch.sum(subset)\n",
    "l.backward()\n",
    "print(type(subset.data))\n",
    "print(type(A.grad.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0.3213 -0.1642 -1.5809  1.2290 -0.3483\n",
       " -0.3959 -0.7861  0.1409 -0.0809  0.1390\n",
       "  1.4156 -1.3082  1.4605  1.3381 -2.8320\n",
       "  1.0430 -0.2916  1.1915  0.0912 -0.0003\n",
       "  0.9861 -0.2945 -0.8929 -2.6913  0.4312\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.5129  1.1571 -0.3850  0.2668  0.5106\n",
       " -1.1796  0.5415 -1.9097  0.7965 -1.6713\n",
       "  1.9068  0.6041  0.5500  0.5249 -0.1018\n",
       "  0.0731  0.6370 -0.1749  0.0695 -1.0927\n",
       " -0.3434 -0.6750 -1.2442  1.3104 -2.1397\n",
       "[torch.FloatTensor of size 2x5x5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(A.chunk(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_layer = nn.Linear(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear (10 -> 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_layer.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.FloatTensor"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_layer.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(20,1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 28,  1, 26, 14, 29, 25, 14])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(30, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GLUE = 5\n",
    "SIGNAL = 50\n",
    "set_size = 40\n",
    "pred_in = 150\n",
    "words = np.random.randn(set_size, pred_in)\n",
    "\n",
    "# Sample a number of clusters (between 1 and 20) present in training instance\n",
    "n_clusters = 1 + np.random.choice(20,1) \n",
    "# Will repeat cluster indices to fill upto set_size\n",
    "rep = (set_size // n_clusters) + 1 \n",
    "\n",
    "# Sample cluster indices \n",
    "clusters = np.random.choice(pred_in // GLUE, n_clusters, replace=False)\n",
    "\n",
    "# Find column indices associated with cluster indices\n",
    "col_idx = np.array([np.arange(i*GLUE, i*GLUE + GLUE) for i in clusters]).flatten()\n",
    "# Repeat indices to fill upto set_size \n",
    "col_idx = np.tile(col_idx, rep)[:(set_size * GLUE)]\n",
    "\n",
    "# Overwrite training data with signal according to column indices\n",
    "words[np.repeat(np.arange(40), GLUE), col_idx] = np.random.normal(SIGNAL, 1, (set_size * GLUE))\n",
    "\n",
    "# Create context \n",
    "context = np.tile(np.sum(words, axis=0), (set_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.sum(words, axis = 0), 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.FloatTensor"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Variable(torch.randn(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 11.1885\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.188507980899885"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
