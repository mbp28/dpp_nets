{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class custom_eig(Function):\n",
    "    \n",
    "    def forward(self, matrix):\n",
    "        assert matrix.size(0) == matrix.size(1)\n",
    "        e, v = torch.eig(matrix, eigenvectors=True)\n",
    "        e = e[:,0]\n",
    "        self.save_for_backward(e, v)\n",
    "        return e, v\n",
    "\n",
    "    def backward(self, grad_e, grad_v):\n",
    "        e, v = self.saved_tensors\n",
    "        dim = v.size(0)\n",
    "        E = e.expand(dim, dim) - e.expand(dim, dim).t()\n",
    "        I = E.new(dim, dim).copy_(torch.eye(dim))\n",
    "        F = (1 / (E + I)) - I \n",
    "        M = grad_e.diag() + F * (v.t().mm(grad_v))\n",
    "        grad_matrix = v.mm(M).mm(v.t())\n",
    "        return grad_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_col(matrix, col_ix):\n",
    "    \n",
    "    if col_ix == 0:\n",
    "        return matrix[:,1:]\n",
    "    \n",
    "    if (col_ix + 1) == matrix.size(1):\n",
    "        return matrix[:,:col_ix]\n",
    "    else:\n",
    "        chunk1 = matrix[:, :col_ix]\n",
    "        chunk2 = matrix[:, (col_ix + 1):]\n",
    "        new_mat = torch.cat([chunk1, chunk2], dim=1)\n",
    "        return new_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DPP(Function):\n",
    "    \n",
    "    def forward(self, vals, vecs):\n",
    "        n = vecs.size(0)\n",
    "        n_vals = vals.size(0)\n",
    "        \n",
    "        index = torch.rand(n_vals) < (vals / (vals + 1))\n",
    "        k = torch.sum(index)\n",
    "        print(k)\n",
    "        if not k:\n",
    "            subset = torch.zeros(n)\n",
    "        \n",
    "        if k == n:\n",
    "            subset =  torch.ones(n)\n",
    "\n",
    "        else:\n",
    "            V = vecs[index.expand_as(vecs)].view(n, -1)\n",
    "            subset = torch.zeros(n)\n",
    "\n",
    "            for i in range(k):\n",
    "                p = torch.sum(V**2, dim=1)\n",
    "                p = torch.cumsum(p / torch.sum(p), 0) # item cumulative probabilities\n",
    "                _, item = (torch.rand(1)[0] < p).max(0)\n",
    "                subset[item[0,0]] = 1\n",
    "\n",
    "                _, j = (torch.abs(V[item[0,0], :]) > 0).max(0)\n",
    "                Vj = V[:, j[0]]\n",
    "                if V.size(1) > 1:\n",
    "                    V = delete_col(V, j[0])\n",
    "                    V = V - torch.mm(Vj.unsqueeze(1), V[item[0,0], :].unsqueeze(1).t() / Vj[item[0,0]])\n",
    "                    # find a new orthogonal basis\n",
    "                    for a in range(V.size(1)):\n",
    "                        for b in range(a):\n",
    "                            V[:,a] = V[:,a] - V[:,a].dot(V[:,b]) * V[:,b]\n",
    "                        V[:,a] = V[:,a] / torch.norm(V[:,a])\n",
    "                    \n",
    "        self.save_for_backward(vals, vecs, subset) \n",
    "        \n",
    "        return subset\n",
    "        \n",
    "    def backward(self, grad_subset):\n",
    "        \n",
    "        vals, vecs, subset = self.saved_tensors\n",
    "        dim = subset.size(0)\n",
    "        matrix = vecs.mm(vals.diag()).mm(vecs.t())\n",
    "        P = torch.eye(dim).masked_select(subset.expand(dim,dim).t().byte()).view(subset.long().sum(),-1)\n",
    "        submatrix = P.mm(matrix).mm(P.t())\n",
    "        subinv = torch.inverse(submatrix)\n",
    "        Pvecs = P.mm(vecs)\n",
    "        \n",
    "        \n",
    "        grad_vals = 1 / vals\n",
    "        grad_vals += Pvecs.t().mm(subinv).mm(Pvecs).diag()\n",
    "        grad_vecs = P.t().mm(subinv).mm(Pvecs).mm(vals.diag())\n",
    "        \n",
    "        return grad_vals, grad_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DPPLayer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DPPLayer, self).__init__()\n",
    "\n",
    "    def forward(self, e, v):\n",
    "        return DPP()(e, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PIPELINE\n",
    "# feed in a tensor of size batch_size * max_set_size * embd_dim\n",
    "# coud possibly be a packed sequence which includes length information for each batch_size\n",
    "# 0) Assume we have created sequences in DataSet (they are already padded)\n",
    "# 1) Collapse to 2D to feed through kernel embedding\n",
    "# 2) Reconstruct using for-loop the kernel matrix L, do eigendecomposition and sample from DPP\n",
    "# 3) New Kernel should batch_size * alpha_iter * embd_dim (contains summed_selection for each batch + iteration)\n",
    "# 4) Collapse to 2D and feed through prediction network\n",
    "# 5) Get something of size (batch_size x alpha_iter) * target_dim, make target compatible with this\n",
    "# 6) Backpropagate the loss\n",
    "mask = data.abs().sum(2).sign().squeeze()\n",
    "lengths = mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(vector, size):\n",
    "    if vector.size(0) == size:\n",
    "        return vector\n",
    "    else:\n",
    "        pads = size - vector.size(0)\n",
    "        return torch.cat([vector, Variable(vector.data.new(pads).copy_(torch.zeros(pads)))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  0  1  1  0\n",
       "  0  1  1  1\n",
       "  1  0  0  0\n",
       "  1  1  1  1\n",
       "  1  0  1  0\n",
       " [torch.FloatTensor of size 5x4], Variable containing:\n",
       "  0  1  1\n",
       "  0  1  0\n",
       "  1  0  1\n",
       "  1  1  1\n",
       "  1  1  0\n",
       " [torch.FloatTensor of size 5x3], Variable containing:\n",
       "  0  0  1  1  1  1\n",
       "  1  1  0  1  0  1\n",
       "  1  0  1  0  1  0\n",
       "  0  1  0  1  0  1\n",
       "  0  1  1  0  0  0\n",
       " [torch.FloatTensor of size 5x6], Variable containing:\n",
       "  1  0  1  1\n",
       "  0  1  1  0\n",
       "  1  0  1  1\n",
       "  0  1  1  1\n",
       "  1  0  1  1\n",
       " [torch.FloatTensor of size 5x4], Variable containing:\n",
       "  0  1  1  1  0\n",
       "  1  0  0  0  1\n",
       "  1  0  0  1  0\n",
       "  0  0  0  1  1\n",
       "  0  0  1  0  0\n",
       " [torch.FloatTensor of size 5x5]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       " [torch.FloatTensor of size 5x2], \n",
       "  0  0  0\n",
       "  0  0  0\n",
       "  0  0  0\n",
       "  0  0  0\n",
       "  0  0  0\n",
       " [torch.FloatTensor of size 5x3], \n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 5], \n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       " [torch.FloatTensor of size 5x2], \n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 5x1]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.zeros(alpha_iter,i) for i in (max_set_size - length.data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.FloatTensor with no dimension]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.zeros(0),torch.zeros(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hook(i, j):\n",
    "    def my_print(module, grad_in, grad_out):\n",
    "        print(i,j, loss_list[i][j])\n",
    "    return my_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "register_backward_hook() missing 1 required positional argument: 'hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-655102da90d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPPLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mDPPLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_with_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_set_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: register_backward_hook() missing 1 required positional argument: 'hook'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set up data\n",
    "batch_size = 5\n",
    "max_set_size = 6\n",
    "feat_dim = 7\n",
    "target_dim = 3\n",
    "alpha_iter = 5\n",
    "hidden_dim = 10\n",
    "alpha_iter = 2\n",
    "kernel = nn.Linear(feat_dim, hidden_dim)\n",
    "predictor = nn.Linear(feat_dim, target_dim)\n",
    "\n",
    "data = torch.zeros(batch_size, max_set_size, feat_dim)\n",
    "data[0,:4] = torch.randn(4,feat_dim)\n",
    "data[1,:3] = torch.randn(3,feat_dim)\n",
    "data[2,:6] = torch.randn(6,feat_dim)\n",
    "data[3,:4] = torch.randn(4,feat_dim)\n",
    "data[4,:5] = torch.randn(5,feat_dim)\n",
    "data = Variable(data)\n",
    "target = Variable(torch.randn(batch_size, target_dim))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Forward pass\n",
    "mask = data.abs().sum(2).sign().byte()\n",
    "#length = mask.sum(1).squeeze()\n",
    "batch_kernel = kernel(data.masked_select(mask.expand_as(data)).view(-1, feat_dim))\n",
    "#batch_kernel.sum().backward()\n",
    "s = 0\n",
    "samples = [[] for i in range(batch_size)]\n",
    "\n",
    "for i, e in enumerate(length.data):\n",
    "    \n",
    "    A = batch_kernel[s:e]\n",
    "    L = A.mm(A.t())\n",
    "    e, v = custom_eig()(L)\n",
    "    \n",
    "    for j in range(alpha_iter):\n",
    "        subset = DPPLayer()(e,v)\n",
    "        DPPLayer.register_backward_hook(my_hook(i,j))\n",
    "        sample = pad_with_zeros(subset, max_set_size)\n",
    "        samples[i].append(sample)\n",
    "        \n",
    "samples = [torch.stack(i) for i in samples]\n",
    "reps = [samples[i].mm(data[i]) for i in range(batch_size)]\n",
    "big = torch.cat(reps)\n",
    "predictions = predictor(big).view(batch_size, alpha_iter, target_dim)\n",
    "target = target.unsqueeze(1).expand(batch_size, alpha_iter, target_dim)\n",
    "loss = criterion(predictions, target)\n",
    "loss_list = list(((predictions - target)**2).mean(2).view(-1).data)\n",
    "loss_list = list(((predictions - target)**2).mean(2).data)\n",
    "loss_list = [list(i.view(-1)) for i in loss_list]\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = list(((predictions - target)**2).mean(2).data)\n",
    "loss_list = [list(i.view(-1)) for i in loss_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  1  1  1  1  0  0\n",
       "  0  1  1  1  0  0\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  0  0  0  0  0  0\n",
       "  1  0  0  0  0  0\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  1  0  1  1  1  0\n",
       "  1  1  0  1  1  1\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  1  1  1  0  0  0\n",
       "  1  1  0  1  0  0\n",
       " [torch.FloatTensor of size 2x6], Variable containing:\n",
       "  0  1  0  1  0  0\n",
       "  0  1  1  0  0  0\n",
       " [torch.FloatTensor of size 2x6]]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9952688813209534, 0.29814091324806213],\n",
       " [0.5694721341133118, 2.242947816848755],\n",
       " [2.1085400581359863, 1.6003299951553345],\n",
       " [0.734687328338623, 0.4700922667980194],\n",
       " [2.690185546875, 2.690185546875]]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.9953\n",
       "  0.2981\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.5695\n",
       "  2.2429\n",
       "\n",
       "(2 ,.,.) = \n",
       "  2.1085\n",
       "  1.6003\n",
       "\n",
       "(3 ,.,.) = \n",
       "  0.7347\n",
       "  0.4701\n",
       "\n",
       "(4 ,.,.) = \n",
       "  2.6902\n",
       "  2.6902\n",
       "[torch.FloatTensor of size 5x2x1]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predictions - target)**2).mean(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = med[start:end]\n",
    "    L = kernel.mm(kernel.t())\n",
    "    e, v = custom_eig()(L)\n",
    "    for j in range(3):\n",
    "        subset = DPP()(e, v)\n",
    "        my_list[i].append(subset)\n",
    "    start = end\n",
    "new_list = [torch.stack(l) for l in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x113107900>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PYTHON \n",
    "# FULL CHECK FOR EIGENVALUE AND EIGENVECTOR GRADIENTS\n",
    "# INCLUDING THE ACTUAL CALCULATION OF THE GRADIENTS\n",
    "# THIS SHOULD BE USEFUL\n",
    "# This works in NUMPY\n",
    "# Let's transfer it to Pytorch\n",
    "\n",
    "# General Set-up\n",
    "N = 4\n",
    "A = 0.1 * np.random.randn(N, N) + np.diag(np.arange(1, N+1))\n",
    "B = np.random.randn(N, N)\n",
    "I = np.eye(N)\n",
    "dA = np.random.randn(N, N)\n",
    "dB = np.random.randn(N, N)\n",
    "bC = np.random.randn(N, N)\n",
    "eps = 1e-20\n",
    "epsi = 1 / eps\n",
    "Ae = A + 1j*eps*dA\n",
    "Be = B + 1j*eps*dB\n",
    "\n",
    "# EIGEN Set-up\n",
    "De, Ue = np.linalg.eig(Ae)\n",
    "D = np.real(De)\n",
    "U = np.real(Ue)\n",
    "\n",
    "# make dC diagonal equal to zero\n",
    "Ue = Ue.dot(np.diag(1 / np.diag(np.linalg.inv(U).dot(Ue))))\n",
    "E = np.outer(np.ones(N), D) - np.outer(D, np.ones(N))\n",
    "F = 1 / (E + np.eye(N)) - np.eye(N)\n",
    "P = np.linalg.inv(U).dot(dA.dot(U))\n",
    "dD = np.eye(N) * P\n",
    "dU = U.dot(F*P)\n",
    "\n",
    "bD = np.diag(np.random.randn(N))\n",
    "bU = np.random.randn(N,N)\n",
    "bD = bD + F * (U.T.dot(bU))\n",
    "bA = np.linalg.inv(U.T).dot(bD.dot(U.T))\n",
    "print('eigenvalues and eigenvectors')\n",
    "print('CVT error: ', np.linalg.norm(np.diag(dD)-epsi*np.imag(De)))\n",
    "print('CVT error: ', np.linalg.norm(dU-epsi*np.imag(Ue)))\n",
    "print('adj error: ',np.sum(dA*bA)-np.sum(dD*bD)-np.sum(dU*bU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set-up\n",
    "N = 3\n",
    "A = torch.randn(N,N).double()\n",
    "A = A.mm(A.t())\n",
    "#A = torch.Tensor(A).float()\n",
    "e, v = torch.eig(A, eigenvectors=True)\n",
    "e = e[:,0]\n",
    "\n",
    "# Random perturbation for forward\n",
    "dA = torch.randn(N,N)\n",
    "E = e.expand(N,N) - e.expand(N,N).t()\n",
    "F = 1 / (E + torch.eye(N)) - torch.eye(N)\n",
    "P = v.inverse().mm(dA).mm(v)\n",
    "de = torch.eye(N) * P\n",
    "dv = v.mm(F * P)\n",
    "\n",
    "# random perturbation for backward\n",
    "be = torch.randn(N).diag()\n",
    "bv = torch.randn(N, N)\n",
    "#be = torch.ones(N).diag()\n",
    "#bv = torch.ones(N, N)\n",
    "med = be + F * (v.t().mm(bv))\n",
    "bA = v.t().inverse().mm(med).mm(v.t())\n",
    "\n",
    "print('adj error: ',torch.sum(dA*bA)-torch.sum(de*be)-torch.sum(dv*bv))\n",
    "bA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_var = Variable(A, requires_grad=True)\n",
    "e_var, v_var = custom_eig()(A_var)\n",
    "be_var = torch.FloatTensor(be.diag())\n",
    "bv_var = torch.FloatTensor(bv)\n",
    "e_var.backward(be_var, retain_variables=True)\n",
    "v_var.backward(bv_var)\n",
    "bA = A_var.grad.data\n",
    "bA\n",
    "\n",
    "# artificial forward pass - simply re-use the tensors from the other cell\n",
    "# in fact by showing that the backward gradients agree, we have already established proof of concept\n",
    "print('adj error: ',torch.sum(dA*bA)-torch.sum(de*be)-torch.sum(dv*bv))\n",
    "bA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PYTHON\n",
    "# it's clear that this does not check the singular vectors :((( \n",
    "# But this is still useful. \n",
    "import numpy as np\n",
    "\n",
    "# General Set-up\n",
    "N = 5\n",
    "A = 0.1 * np.random.randn(N, N) + np.diag(np.arange(1, N+1))\n",
    "B = np.random.randn(N, N)\n",
    "I = np.eye(N)\n",
    "dA = np.random.randn(N, N)\n",
    "dB = np.random.randn(N, N)\n",
    "bC = np.random.randn(N, N)\n",
    "eps = 1e-20\n",
    "epsi = 1 / eps\n",
    "Ae = A + 1j*eps*dA\n",
    "Be = B + 1j*eps*dB\n",
    "\n",
    "# SVD Set-up\n",
    "u, s, vT = np.linalg.svd(A)\n",
    "De = np.linalg.eigvals(Ae.T.dot(Ae))\n",
    "De = np.sort(De)[::-1]\n",
    "D = np.real(De)\n",
    "\n",
    "# forward propagation \n",
    "dA = dA\n",
    "dS = np.diag(I * u.T.dot(dA).dot(vT.T))\n",
    "\n",
    "# backward gradients\n",
    "bS = np.random.randn(N) # gradients wrt singular values\n",
    "bA = u.dot(np.diag(bS)).dot(vT) # backpropagated gradient wrt to matrix A\n",
    "\n",
    "print('singular value')\n",
    "print('svd error: ', (np.linalg.norm(s-np.sqrt(D))))\n",
    "\n",
    "# Forward Check based on complex matrices\n",
    "print('CVT error: ', (np.linalg.norm(2*s*dS - epsi*np.imag(De))))\n",
    "\n",
    "# Backward Check, these are essentially two traces!!\n",
    "print('adj error: ',np.sum(dA*bA)-np.sum(dS*bS))\n",
    "\n",
    "# I should be able to use the same identity for my testing purposes!!!\n",
    "# trace(bC.T * dC) = trace(bA.T * dA) + trace(bB.T * dB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try to do it for the eigendecomposition first\n",
    "# We are doing it in PyTorch \n",
    "\n",
    "# Inputs: matrix A\n",
    "# Outputs: e, v\n",
    "N = 5\n",
    "temp = torch.randn(N, N)\n",
    "\n",
    "# Set-up A, e and v\n",
    "A = temp.mm(temp.t())\n",
    "e, v = torch.eig(A, eigenvectors=True)\n",
    "e = e[:,0]\n",
    "\n",
    "# random forward perturbation\n",
    "dA = torch.randn(N,N)\n",
    "de = (torch.ones(N).diag() * (v.inverse().mm(dA).mm(v))).diag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(5,5)\n",
    "A = Variable(data, requires_grad=True)\n",
    "vals, vecs = custom_eig()(A)\n",
    "subset = DPP()(vals, vecs)\n",
    "subset\n",
    "loss = subset.sum()\n",
    "loss.backward()\n",
    "A.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = data.abs().sum(2).sign().squeeze()\n",
    "lengths = mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable(torch.arange(0,max_set_size).expand_as(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scalability - Flexible batch_size\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(10)\n",
    "batch_size = 5\n",
    "max_set_size = 6\n",
    "feat_dim = 4\n",
    "hidden_dim = 300\n",
    "data = torch.randn(batch_size, max_set_size, feat_dim)\n",
    "model = nn.Linear(feat_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make it tensor-ready\n",
    "mask, _ = data.abs().max(dim=2)\n",
    "length = mask.sign().sum(dim=1).squeeze()\n",
    "mask = mask.sign().expand_as(data).byte()\n",
    "\n",
    "my_input = Variable(data, requires_grad=True)\n",
    "compressed = my_input.masked_select(Variable(mask)).view(-1,feat_dim)\n",
    "med = model(compressed)\n",
    "\n",
    "# now do the eigendecomposition (for this need to re-assemble the tensor again)\n",
    "# this probably needs a for-loop :(((((\n",
    "# for i in range(batch_size):\n",
    "start = 0 \n",
    "my_list = [[] for i in range(batch_size)]\n",
    "for i, end in enumerate(length.cumsum(0).long()):\n",
    "    kernel = med[start:end]\n",
    "    L = kernel.mm(kernel.t())\n",
    "    e, v = custom_eig()(L)\n",
    "    for j in range(3):\n",
    "        subset = DPP()(e, v)\n",
    "        my_list[i].append(subset)\n",
    "    start = end\n",
    "new_list = [torch.stack(l) for l in my_list]\n",
    "\n",
    "#loss = torch.stack(my_list)\n",
    "#final = loss.sum()\n",
    "#final.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to pad zeros\n",
    "new_list = [torch.stack(l) for l in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I want to create a tensor of size batch_size * alpha_iter * embd_dim\n",
    "# Or I want to create a tensor of size batch_size * subset (needs to be padded with zeros) * alpha_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "batch_size = 3\n",
    "max_length = 3\n",
    "hidden_size = 2\n",
    "n_layers =1\n",
    "\n",
    "# container\n",
    "batch_in = torch.zeros((batch_size, 1, max_length))\n",
    "\n",
    "#data\n",
    "vec_1 = torch.FloatTensor([[1, 2, 3]])\n",
    "vec_2 = torch.FloatTensor([[1, 2, 0]])\n",
    "vec_3 = torch.FloatTensor([[1, 0, 0]])\n",
    "\n",
    "batch_in[0] = vec_1\n",
    "batch_in[1] = vec_2\n",
    "batch_in[2] = vec_3\n",
    "\n",
    "batch_in = Variable(batch_in)\n",
    "\n",
    "seq_lengths = [3,2,1] # list of integers holding information about the batch size at each sequence step\n",
    "\n",
    "# pack it\n",
    "pack = torch.nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "\n",
    "# initialize\n",
    "rnn = nn.RNN(max_length, hidden_size, n_layers, batch_first=True) \n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "\n",
    "#forward \n",
    "out, _ = rnn(pack, h0)\n",
    "\n",
    "# unpack\n",
    "unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
