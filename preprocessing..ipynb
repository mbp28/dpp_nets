{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '/Users/Max/data/beer_reviews/reviews.all.train.txt.gz'\n",
    "val_path = '/Users/Max/data/beer_reviews/reviews.all.heldout.txt.gz'\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open(train_path, 'rt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210000/210000 [43:14<00:00, 80.93it/s]  \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for line in tqdm.tqdm(lines):\n",
    "    target, _, review = line.partition(\"\\t\")\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    # parsing in spacy style\n",
    "    words = [tuple([token.text]) for token in doc]\n",
    "    sents = [tuple([token.text for token in sent]) for sent in doc.sents]\n",
    "    chunks = [tuple([word.text for word in token.subtree if word.text != '\\n' and word.text != '\\t']) for token in doc]\n",
    "    \n",
    "    # creating encodings\n",
    "    enc_words  = target + '\\D' + '\\T'.join(['\\W'.join(tup) for tup in words])\n",
    "    enc_sents  = target + '\\D' + '\\T'.join(['\\W'.join(tup) for tup in sents])\n",
    "    enc_chunks = target + '\\D' + '\\T'.join(['\\W'.join(tup) for tup in chunks]) + '\\n'\n",
    "    \n",
    "    with gzip.open('/Users/Max/data/beer_reviews/reviews.all.train.words.txt.gz', 'at') as f:\n",
    "        f.write(enc_words)\n",
    "    \n",
    "    with gzip.open('/Users/Max/data/beer_reviews/reviews.all.train.chunks.txt.gz', 'at') as f:\n",
    "        f.write(enc_chunks)\n",
    "        \n",
    "    with gzip.open('/Users/Max/data/beer_reviews/reviews.all.train.sents.txt.gz', 'at') as f:\n",
    "        f.write(enc_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('/Users/Max/data/beer_reviews/reviews.all.train.chunks.txt.gz', 'rt') as f:\n",
    "    my_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i',),\n",
       " ('i',\n",
       "  'remember',\n",
       "  'this',\n",
       "  'beer',\n",
       "  'being',\n",
       "  'better',\n",
       "  'than',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'),\n",
       " ('this',),\n",
       " ('this', 'beer'),\n",
       " ('this', 'beer', 'being', 'better', 'than', 'it', 'was'),\n",
       " ('better', 'than', 'it', 'was'),\n",
       " ('than',),\n",
       " ('it',),\n",
       " ('than', 'it', 'was'),\n",
       " ('.',),\n",
       " ('i',),\n",
       " ('i',\n",
       "  'bought',\n",
       "  'a',\n",
       "  'six',\n",
       "  'pack',\n",
       "  'and',\n",
       "  'expected',\n",
       "  'a',\n",
       "  'decent',\n",
       "  'hoppy',\n",
       "  'ipa',\n",
       "  '.'),\n",
       " ('a',),\n",
       " ('six',),\n",
       " ('a', 'six', 'pack'),\n",
       " ('and',),\n",
       " ('expected', 'a', 'decent', 'hoppy', 'ipa'),\n",
       " ('a',),\n",
       " ('decent',),\n",
       " ('hoppy',),\n",
       " ('a', 'decent', 'hoppy', 'ipa'),\n",
       " ('.',),\n",
       " ('what',),\n",
       " ('i',),\n",
       " ('what', 'i', 'tasted'),\n",
       " ('what', 'i', 'tasted', 'was', 'an', 'oxidized', 'malty', 'amber', '.'),\n",
       " ('an',),\n",
       " ('oxidized',),\n",
       " ('malty',),\n",
       " ('an', 'oxidized', 'malty', 'amber'),\n",
       " ('.',),\n",
       " ('it',),\n",
       " ('it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'bad',\n",
       "  'beer',\n",
       "  ',',\n",
       "  'just',\n",
       "  'not',\n",
       "  'a',\n",
       "  'great',\n",
       "  'ipa',\n",
       "  '.'),\n",
       " ('not',),\n",
       " ('a',),\n",
       " ('bad',),\n",
       " ('a', 'bad', 'beer', ',', 'just', 'not', 'a', 'great', 'ipa'),\n",
       " (',',),\n",
       " ('just',),\n",
       " ('not',),\n",
       " ('a',),\n",
       " ('great',),\n",
       " ('not', 'a', 'great', 'ipa'),\n",
       " ('.',),\n",
       " ('i',),\n",
       " ('would',),\n",
       " ('i',\n",
       "  'would',\n",
       "  'have',\n",
       "  'one',\n",
       "  'if',\n",
       "  'i',\n",
       "  'was',\n",
       "  'handed',\n",
       "  'a',\n",
       "  'bottle',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'i',\n",
       "  'will',\n",
       "  'grabbing',\n",
       "  'it',\n",
       "  'off',\n",
       "  'of',\n",
       "  'the',\n",
       "  'shelf',\n",
       "  'any',\n",
       "  'time',\n",
       "  'soon',\n",
       "  '.',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  ','),\n",
       " ('one',),\n",
       " ('if',),\n",
       " ('i',),\n",
       " ('was',),\n",
       " ('if', 'i', 'was', 'handed', 'a', 'bottle'),\n",
       " ('a',),\n",
       " ('a', 'bottle'),\n",
       " (',',),\n",
       " ('but',),\n",
       " ('i',),\n",
       " ('do',),\n",
       " (\"n't\",),\n",
       " ('i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'i',\n",
       "  'will',\n",
       "  'grabbing',\n",
       "  'it',\n",
       "  'off',\n",
       "  'of',\n",
       "  'the',\n",
       "  'shelf',\n",
       "  'any',\n",
       "  'time',\n",
       "  'soon',\n",
       "  '.',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  ','),\n",
       " ('i',),\n",
       " ('will',),\n",
       " ('i',\n",
       "  'will',\n",
       "  'grabbing',\n",
       "  'it',\n",
       "  'off',\n",
       "  'of',\n",
       "  'the',\n",
       "  'shelf',\n",
       "  'any',\n",
       "  'time',\n",
       "  'soon'),\n",
       " ('it',),\n",
       " ('off', 'of', 'the', 'shelf'),\n",
       " ('of', 'the', 'shelf'),\n",
       " ('the',),\n",
       " ('the', 'shelf'),\n",
       " ('any',),\n",
       " ('any', 'time', 'soon'),\n",
       " ('soon',),\n",
       " ('.',),\n",
       " ('on', 'the', 'other', 'hand', ','),\n",
       " ('the',),\n",
       " ('other',),\n",
       " ('the', 'other', 'hand', ','),\n",
       " (',',),\n",
       " ('the',),\n",
       " ('the', 'wife'),\n",
       " ('the',\n",
       "  'wife',\n",
       "  'loves',\n",
       "  'it',\n",
       "  ',',\n",
       "  'so',\n",
       "  'it',\n",
       "  'may',\n",
       "  'show',\n",
       "  'up',\n",
       "  'in',\n",
       "  'our',\n",
       "  'fridge',\n",
       "  'anyway',\n",
       "  '.'),\n",
       " ('it',),\n",
       " (',',),\n",
       " ('so',),\n",
       " ('it',),\n",
       " ('may',),\n",
       " ('so', 'it', 'may', 'show', 'up', 'in', 'our', 'fridge', 'anyway'),\n",
       " ('up',),\n",
       " ('in', 'our', 'fridge'),\n",
       " ('our',),\n",
       " ('our', 'fridge'),\n",
       " ('anyway',),\n",
       " ('.',),\n",
       " ('\\n',)]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode\n",
    "obj = my_lines[128383]\n",
    "target, review = obj.split('\\D')\n",
    "[tuple(chunk.split('\\W')) for chunk in review.split('\\T')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.70 0.70 0.90 0.80 0.70\\\\Dclear\\\\Tautumnal\\\\Treddish\\\\Tclear\\\\Wautumnal\\\\Wreddish\\\\Wbrown\\\\W.\\\\Wsmall\\\\W,\\\\Wwhite\\\\Wfrothy\\\\Whead\\\\T.\\\\Tsmall\\\\W,\\\\Wwhite\\\\Wfrothy\\\\Whead\\\\T,\\\\Twhite\\\\Tfrothy\\\\Twhite\\\\Wfrothy\\\\Whead\\\\T.\\\\Tsweet\\\\Tbaking\\\\T.\\\\Wsweet\\\\Wbaking\\\\Wspices\\\\Won\\\\Wthe\\\\Wnose\\\\W.\\\\Wfull\\\\Wtextured\\\\Wbody\\\\W,\\\\Wsmooth\\\\Wand\\\\Wcreamy\\\\W.\\\\Whuge\\\\Wspicey\\\\W,\\\\Wsugary\\\\Wflavor\\\\W...\\\\Wfinishes\\\\Wdry\\\\Wfrom\\\\Wa\\\\Wgentle\\\\Whop\\\\Wbite\\\\W.\\\\Wquite\\\\Wdifferent\\\\Wthan\\\\Wmost\\\\Wpumpkin\\\\Wales\\\\W,\\\\Wand\\\\Wis\\\\Wbetter\\\\Wfor\\\\Wit\\\\W.\\\\Wspice\\\\Wprofile\\\\Wis\\\\Winteresting\\\\Wwithout\\\\Wbeing\\\\Woverwhelming\\\\W.\\\\Wa\\\\Wgreat\\\\Wfall\\\\Wtreat\\\\W.\\\\Ton\\\\Wthe\\\\Wnose\\\\Tthe\\\\Tthe\\\\Wnose\\\\T.\\\\Tfull\\\\Ttextured\\\\T.\\\\Wfull\\\\Wtextured\\\\Wbody\\\\W,\\\\Wsmooth\\\\Wand\\\\Wcreamy\\\\T,\\\\Tsmooth\\\\Wand\\\\Wcreamy\\\\Tand\\\\Tcreamy\\\\T.\\\\Thuge\\\\T.\\\\Whuge\\\\Wspicey\\\\W,\\\\Wsugary\\\\Wflavor\\\\W...\\\\T,\\\\Tsugary\\\\Tsugary\\\\Wflavor\\\\T...\\\\T.\\\\Wfull\\\\Wtextured\\\\Wbody\\\\W,\\\\Wsmooth\\\\Wand\\\\Wcreamy\\\\W.\\\\Whuge\\\\Wspicey\\\\W,\\\\Wsugary\\\\Wflavor\\\\W...\\\\Wfinishes\\\\Wdry\\\\Wfrom\\\\Wa\\\\Wgentle\\\\Whop\\\\Wbite\\\\W.\\\\Wquite\\\\Wdifferent\\\\Wthan\\\\Wmost\\\\Wpumpkin\\\\Wales\\\\W,\\\\Wand\\\\Wis\\\\Wbetter\\\\Wfor\\\\Wit\\\\W.\\\\Tdry\\\\Wfrom\\\\Wa\\\\Wgentle\\\\Whop\\\\Wbite\\\\Tfrom\\\\Wa\\\\Wgentle\\\\Whop\\\\Wbite\\\\Ta\\\\Tgentle\\\\Thop\\\\Ta\\\\Wgentle\\\\Whop\\\\Wbite\\\\T.\\\\Tquite\\\\Tquite\\\\Wdifferent\\\\Wthan\\\\Wmost\\\\Wpumpkin\\\\Wales\\\\Tthan\\\\Wmost\\\\Wpumpkin\\\\Wales\\\\Tmost\\\\Tpumpkin\\\\Tmost\\\\Wpumpkin\\\\Wales\\\\T,\\\\Tand\\\\Tis\\\\Wbetter\\\\Wfor\\\\Wit\\\\Tbetter\\\\Wfor\\\\Wit\\\\Tfor\\\\Wit\\\\Tit\\\\T.\\\\Tspice\\\\Tspice\\\\Wprofile\\\\Tspice\\\\Wprofile\\\\Wis\\\\Winteresting\\\\Wwithout\\\\Wbeing\\\\Woverwhelming\\\\W.\\\\Tinteresting\\\\Twithout\\\\Wbeing\\\\Woverwhelming\\\\Tbeing\\\\Woverwhelming\\\\Toverwhelming\\\\T.\\\\Ta\\\\Tgreat\\\\Tfall\\\\Ta\\\\Wgreat\\\\Wfall\\\\Wtreat\\\\T.\\\\T\\n'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lines[129322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parsing in spacy style\n",
    "words = [tuple([token.text]) for token in doc]\n",
    "sents = [tuple([token.text for token in sent]) for sent in doc.sents]\n",
    "chunks = [tuple([word.text for word in token.subtree]) for token in doc]\n",
    "\n",
    "# creating encodings\n",
    "enc_words  = target + '\\D' + '\\T'.join(['\\W'.join(tup) for tup in words])\n",
    "enc_sents  = target + '\\D' + '\\T'.join(['\\W'.join(tup) for tup in sents])\n",
    "enc_chunks = target + '\\D' + '\\T'.join(['\\W'.join(tup) for tup in chunks])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target, review = enc_chunks.split('\\D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.90 0.60 0.80 0.80 0.80'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pour',\n",
       " 'is',\n",
       " 'perfect',\n",
       " 'porter',\n",
       " ':',\n",
       " 'jet',\n",
       " 'black',\n",
       " ',',\n",
       " 'huge',\n",
       " 'off',\n",
       " '-',\n",
       " 'tan',\n",
       " 'head',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.split('\\T')[0].split('\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"poured\\\\Wfrom\\\\Wa\\\\Wbottle\\\\Winto\\\\Wimp\\\\Wpint\\\\Wglass\\\\Wwith\\\\Wdrink\\\\Wby\\\\Wdate\\\\Wof\\\\Wmarch\\\\W2009\\\\W.\\\\Tfrom\\\\Wa\\\\Wbottle\\\\Ta\\\\Ta\\\\Wbottle\\\\Tinto\\\\Wimp\\\\Wpint\\\\Wglass\\\\Wwith\\\\Wdrink\\\\Wby\\\\Wdate\\\\Wof\\\\Wmarch\\\\W2009\\\\Timp\\\\Tpint\\\\Timp\\\\Wpint\\\\Wglass\\\\Wwith\\\\Wdrink\\\\Wby\\\\Wdate\\\\Wof\\\\Wmarch\\\\W2009\\\\Twith\\\\Wdrink\\\\Wby\\\\Wdate\\\\Wof\\\\Wmarch\\\\W2009\\\\Tdrink\\\\Wby\\\\Wdate\\\\Wof\\\\Wmarch\\\\W2009\\\\Tby\\\\Wdate\\\\Wof\\\\Wmarch\\\\W2009\\\\Tdate\\\\Wof\\\\Wmarch\\\\W2009\\\\Tof\\\\Wmarch\\\\W2009\\\\Tmarch\\\\W2009\\\\T2009\\\\T.\\\\Tpours\\\\Wa\\\\Wclear\\\\Wlight\\\\Wcopper\\\\Wwith\\\\Wa\\\\Wlittle\\\\Whead\\\\W,\\\\Wvery\\\\Wlight\\\\Wretention\\\\W.\\\\Ta\\\\Tclear\\\\Tlight\\\\Ta\\\\Wclear\\\\Wlight\\\\Wcopper\\\\Wwith\\\\Wa\\\\Wlittle\\\\Whead\\\\W,\\\\Wvery\\\\Wlight\\\\Twith\\\\Wa\\\\Wlittle\\\\Whead\\\\W,\\\\Ta\\\\Tlittle\\\\Ta\\\\Wlittle\\\\Whead\\\\W,\\\\T,\\\\Tvery\\\\Tvery\\\\Wlight\\\\Tretention\\\\T.\\\\Tsmell\\\\Twas\\\\Tsmell\\\\Wwas\\\\Wlacking\\\\Wwith\\\\Wbarely\\\\Wany\\\\Whop\\\\Wscent\\\\Wcoming\\\\Wfrom\\\\Wthe\\\\Wpour\\\\W.\\\\Twith\\\\Wbarely\\\\Wany\\\\Whop\\\\Wscent\\\\Wcoming\\\\Wfrom\\\\Wthe\\\\Wpour\\\\Tbarely\\\\Tany\\\\Thop\\\\Tbarely\\\\Wany\\\\Whop\\\\Wscent\\\\Wcoming\\\\Wfrom\\\\Wthe\\\\Wpour\\\\Tcoming\\\\Wfrom\\\\Wthe\\\\Wpour\\\\Tfrom\\\\Wthe\\\\Wpour\\\\Tthe\\\\Tthe\\\\Wpour\\\\T.\\\\Ti\\\\Ti\\\\Wthink\\\\Wi\\\\Wsmelled\\\\Wmore\\\\Wmalts\\\\Wthan\\\\Whops\\\\W.\\\\Ti\\\\Ti\\\\Wsmelled\\\\Wmore\\\\Wmalts\\\\Wthan\\\\Whops\\\\Tmore\\\\Tmore\\\\Wmalts\\\\Wthan\\\\Whops\\\\Tthan\\\\Whops\\\\Thops\\\\T.\\\\Ttaste\\\\Ttaste\\\\Wwas\\\\Wslightly\\\\Wbitter\\\\Wbut\\\\Wrather\\\\Wwashed\\\\Wout\\\\W.\\\\Tslightly\\\\Tslightly\\\\Wbitter\\\\Wbut\\\\Tbut\\\\Trather\\\\Trather\\\\Wwashed\\\\Wout\\\\Tout\\\\T.\\\\Tit\\\\Tit\\\\Wwas\\\\Wvery\\\\Wbitter\\\\Wbut\\\\Wheavy\\\\Wmalt\\\\Wpresence\\\\W.\\\\Tvery\\\\Tvery\\\\Wbitter\\\\Wbut\\\\Wheavy\\\\Tbut\\\\Theavy\\\\Tmalt\\\\Tvery\\\\Wbitter\\\\Wbut\\\\Wheavy\\\\Wmalt\\\\Wpresence\\\\T.\\\\Tthe\\\\Tbest\\\\Tthe\\\\Wbest\\\\Wpart\\\\Tthe\\\\Wbest\\\\Wpart\\\\Wwas\\\\Wthe\\\\Wfinish\\\\W.\\\\Tthe\\\\Tthe\\\\Wfinish\\\\T.\\\\Tcarbonation\\\\Tcarbonation\\\\Wwas\\\\Wstrong\\\\W,\\\\Wa\\\\Wsmidge\\\\Wtoo\\\\Wstrong\\\\Wfor\\\\Wme\\\\Woverall\\\\W,\\\\Wi\\\\Wam\\\\Wnot\\\\Wtoo\\\\Wimpressed\\\\W.\\\\Tstrong\\\\T,\\\\Ta\\\\Ta\\\\Wsmidge\\\\Wtoo\\\\Wstrong\\\\Wfor\\\\Wme\\\\Woverall\\\\Ttoo\\\\Ttoo\\\\Wstrong\\\\Wfor\\\\Wme\\\\Tfor\\\\Wme\\\\Tme\\\\Toverall\\\\T,\\\\Ti\\\\T,\\\\Wi\\\\Wam\\\\Wnot\\\\Wtoo\\\\Wimpressed\\\\Tnot\\\\Ttoo\\\\Ttoo\\\\Wimpressed\\\\T.\\\\Tthe\\\\Tbrooklyn\\\\Tthe\\\\Wbrooklyn\\\\Wlager\\\\Tthe\\\\Wbrooklyn\\\\Wlager\\\\Wis\\\\Wfar\\\\Wmore\\\\Whopped\\\\Wthan\\\\Wthis\\\\Woffering\\\\W.\\\\Tfar\\\\Tmore\\\\Tfar\\\\Wmore\\\\Whopped\\\\Wthan\\\\Wthis\\\\Woffering\\\\Tthan\\\\Wthis\\\\Woffering\\\\Tthis\\\\Tthis\\\\Woffering\\\\T.\\\\Tnot\\\\Tnot\\\\Wsure\\\\Whow\\\\Wold\\\\Wthis\\\\Wbottle\\\\Wis\\\\Wbut\\\\Wit\\\\Wlacks\\\\Whops\\\\W.\\\\Thow\\\\Thow\\\\Wold\\\\Tthis\\\\Tthis\\\\Wbottle\\\\Thow\\\\Wold\\\\Wthis\\\\Wbottle\\\\Wis\\\\Wbut\\\\Wit\\\\Wlacks\\\\Whops\\\\Tbut\\\\Tit\\\\Tit\\\\Wlacks\\\\Whops\\\\Thops\\\\T.\\\\Tbrooklyn\\\\Tbrooklyn\\\\Wbrewery\\\\Tbrooklyn\\\\Wbrewery\\\\Wis\\\\Wa\\\\Wsolid\\\\Wbrewery\\\\Wso\\\\Wi\\\\Wwo\\\\Wn't\\\\Whold\\\\Wthis\\\\Wagainst\\\\Wthem\\\\W.\\\\W\\n\\\\Ta\\\\Tsolid\\\\Ta\\\\Wsolid\\\\Wbrewery\\\\Tso\\\\Ti\\\\Two\\\\Tn't\\\\Ti\\\\Wwo\\\\Wn't\\\\Whold\\\\Wthis\\\\Wagainst\\\\Wthem\\\\W.\\\\W\\n\\\\Tthis\\\\Tagainst\\\\Wthem\\\\Tthem\\\\T.\\\\W\\n\\\\T\\n\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_chunks[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "def read_rationales(path):\n",
    "    \"\"\"\n",
    "    This reads the json.annotations file. \n",
    "    Creates a list of dictionaries, which holds the 994 reviews for which\n",
    "    sentence-level annotations are available. \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    fopen = gzip.open if path.endswith(\".gz\") else open\n",
    "    with fopen(path) as fin:\n",
    "        for line in fin:\n",
    "            item = json.loads(line)\n",
    "            data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import ast\n",
    "nlp = spacy.load('en')\n",
    "anno = '/Users/Max/data/beer_reviews/annotations.json'\n",
    "annotations = read_rationales(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better\n",
    "# For each sentence that deserves a label, we extract the sentence from doc that is closest. \n",
    "\n",
    "def map_sentence(sen, tup):\n",
    "    sen = set([str(token).lower() for token in sen])\n",
    "    n = len(sen) #+ len(tup[0])\n",
    "    s = len(sen & tup[0])\n",
    "    score = s / n\n",
    "    return score\n",
    "\n",
    "# Which sentences deserve a label and what label?\n",
    "ix = 2\n",
    "review = annotations[ix]\n",
    "doc = nlp(ast.literal_eval(annotations[ix]['raw'])['review/text'])\n",
    "all_words = review['x']\n",
    "label_sens = []\n",
    "for label in ['0','1','2']:\n",
    "    label_sens.extend([(set(all_words[s:e]), label) for s, e in review[label]])\n",
    "\n",
    "# Label the sentences in doc\n",
    "sentences = [(sen, set()) for sen in doc.sents]\n",
    "for tup in label_sens:\n",
    "    scores = ([map_sentence(sen, tup) for sen, _ in sentences])\n",
    "    # print(scores)\n",
    "    sentences[scores.index(max(scores))][1].add(tup[1])\n",
    "\n",
    "# Process the sentences\n",
    "words = []\n",
    "chunks= []\n",
    "#mode = 'chunks'\n",
    "\n",
    "for tup in sentences:    \n",
    "    words1 = [tuple([tuple([token.text]),tup[1]]) for token in tup[0]]\n",
    "    chunks1 = [tuple([tuple([word.text for word in token.subtree if word.text != '\\n' and word.text != '\\t']),tup[1]]) for token in tup[0]]\n",
    "    words.extend(words1)\n",
    "    chunks.extend(chunks1)\n",
    "sents = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Very',), {'0'}),\n",
       " (('dark',), {'0'}),\n",
       " (('beer',), {'0'}),\n",
       " (('.',), {'0'}),\n",
       " (('Pours',), {'0'}),\n",
       " (('a',), {'0'}),\n",
       " (('nice',), {'0'}),\n",
       " (('finger',), {'0'}),\n",
       " (('and',), {'0'}),\n",
       " (('a',), {'0'}),\n",
       " (('half',), {'0'}),\n",
       " (('of',), {'0'}),\n",
       " (('creamy',), {'0'}),\n",
       " (('foam',), {'0'}),\n",
       " (('and',), {'0'}),\n",
       " (('stays',), {'0'}),\n",
       " (('throughout',), {'0'}),\n",
       " (('the',), {'0'}),\n",
       " (('beer',), {'0'}),\n",
       " (('.',), {'0'}),\n",
       " (('\\t\\t',), {'0'}),\n",
       " (('Smells',), {'1'}),\n",
       " (('of',), {'1'}),\n",
       " (('coffee',), {'1'}),\n",
       " (('and',), {'1'}),\n",
       " (('roasted',), {'1'}),\n",
       " (('malt',), {'1'}),\n",
       " (('.',), {'1'}),\n",
       " (('\\t\\t',), {'1'}),\n",
       " (('Has',), set()),\n",
       " (('a',), set()),\n",
       " (('major',), set()),\n",
       " (('coffee',), set()),\n",
       " (('-',), set()),\n",
       " (('like',), set()),\n",
       " (('taste',), set()),\n",
       " (('with',), set()),\n",
       " (('hints',), set()),\n",
       " (('of',), set()),\n",
       " (('chocolate',), set()),\n",
       " (('.',), set()),\n",
       " (('If',), set()),\n",
       " (('you',), set()),\n",
       " (('like',), set()),\n",
       " (('black',), set()),\n",
       " (('coffee',), set()),\n",
       " ((',',), set()),\n",
       " (('you',), set()),\n",
       " (('will',), set()),\n",
       " (('love',), set()),\n",
       " (('this',), set()),\n",
       " (('Porter',), set()),\n",
       " (('.',), set()),\n",
       " (('\\t\\t',), set()),\n",
       " (('Creamy',), {'2'}),\n",
       " (('smooth',), {'2'}),\n",
       " (('mouthfeel',), {'2'}),\n",
       " (('and',), {'2'}),\n",
       " (('definitely',), {'2'}),\n",
       " (('gets',), {'2'}),\n",
       " (('smoother',), {'2'}),\n",
       " (('on',), {'2'}),\n",
       " (('the',), {'2'}),\n",
       " (('palate',), {'2'}),\n",
       " (('once',), {'2'}),\n",
       " (('it',), {'2'}),\n",
       " (('warms',), {'2'}),\n",
       " (('.',), {'2'}),\n",
       " (('\\t\\t',), {'2'}),\n",
       " (('It',), set()),\n",
       " ((\"'s\",), set()),\n",
       " (('an',), set()),\n",
       " (('ok',), set()),\n",
       " (('Porter',), set()),\n",
       " (('but',), set()),\n",
       " (('I',), set()),\n",
       " (('feel',), set()),\n",
       " (('there',), set()),\n",
       " (('are',), set()),\n",
       " (('much',), set()),\n",
       " (('better',), set()),\n",
       " (('one',), set()),\n",
       " ((\"'s\",), set()),\n",
       " (('out',), set()),\n",
       " (('there',), set()),\n",
       " (('.',), set())]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Very dark beer. Pours a nice finger and a half of creamy foam and stays throughout the beer.\t\t,\n",
       "  {'0'}),\n",
       " (Smells of coffee and roasted malt.\t\t, {'1'}),\n",
       " (Has a major coffee-like taste with hints of chocolate., set()),\n",
       " (If you like black coffee, you will love this Porter.\t\t, set()),\n",
       " (Creamy smooth mouthfeel and definitely gets smoother on the palate once it warms.\t\t,\n",
       "  {'2'}),\n",
       " (It's an ok Porter but I feel there are much better one's out there., set())]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Very dark beer. Pours a nice finger and a half of creamy foam and stays throughout the beer.\t\tSmells of coffee and roasted malt.\t\tHas a major coffee-like taste with hints of chocolate. If you like black coffee, you will love this Porter.\t\tCreamy smooth mouthfeel and definitely gets smoother on the palate once it warms.\t\tIt's an ok Porter but I feel there are much better one's out there."
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 4], [4, 20]], [[20, 27]], [[49, 63]]]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[review[label] for label in ['0','1','2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
